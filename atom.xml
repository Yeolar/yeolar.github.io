<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://yeolar.github.io</id>
    <title>互联网调研</title>
    <updated>2020-11-16T01:25:11.833Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://yeolar.github.io"/>
    <link rel="self" href="https://yeolar.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://yeolar.github.io/images/avatar.png</logo>
    <icon>https://yeolar.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, 互联网调研</rights>
    <entry>
        <title type="html"><![CDATA[黄奇帆：这一领域可能产生几十家万亿级企业]]></title>
        <id>https://yeolar.github.io/post/huang-qi-fan-zhe-yi-ling-yu-ke-neng-chan-sheng-ji-shi-jia-wan-yi-ji-qi-ye/</id>
        <link href="https://yeolar.github.io/post/huang-qi-fan-zhe-yi-ling-yu-ke-neng-chan-sheng-ji-shi-jia-wan-yi-ji-qi-ye/">
        </link>
        <updated>2020-11-16T01:17:19.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>我们回顾经济史，每一个时代的风口都会催生一批独角兽……所谓的一个个时代，大体上可以用20年划一个时代。比如六七十年代，中国人说的，收音机、自行车、手表、缝纫机……八九十年代的4大件就是空调、洗衣机、冰箱和电视机……到了新世纪的20年，进入家庭的四大件，那就是轿车、笔记本电脑、手机、液晶面板形成的各种显示设备。最近这10年，实际上就出现了互联网消费时代的企业，比如阿里巴巴、腾讯、百度，美团等等。</p>
</blockquote>
<p>“每个时代总会有一批企业跟千家万户的生活融合在一起，这种产品需求量规模巨大，谁能在这样的一个巨大的产品需求和产业链当中崛起，成为主体的企业，一般都会成为世界级的大企业。”</p>
<p>“如果说资本市场是股权投资的战场，独角兽是科创企业的主力军，私募基金、风险投资基金就是市场化选择独角兽的‘啄木鸟 ’。”</p>
<p>“如果说中国的消费互联网市场目前能够容纳几家万亿级的企业，在产业互联网领域，今后有可能产生或者容纳几十家同等规模的创新企业。这是一个巨大的蓝海，今后的独角兽将主要产生于工业互联网的体系。”</p>
<p>“中央提出在中国要建设推动一批德国的弗劳恩霍夫研究所。中央文件推荐要建某一种研究所，大家以前很少看到，到底什么是弗劳恩霍夫研究所呢？其实它就是一个科学技术转移机构。这个研究所并不搞科研创新活动，他所有的工作人员就是科学技术的经纪人，研究所的功能主要特征就是我们中国人说的‘婚姻介绍所’，做红娘的。 ”</p>
<p>“我们国家去年的研发费占GDP的2.2%，100万亿的GDP差不多是2.2万亿的研发费，这个研发费仅次于美国的总量，我们排第二，所以这个量投入不小，但是我们研发费集中度不高。特别是发达国家，研发费的20%左右集中在基础性的、核心的、高科技的研发方面，也就是我们说的核高基。在这个意义上讲，我们国家去年核高基领域的研发费总投入，仅仅是我们全部研发费的5%，意思就是我们 2.2万亿的研发费，实际上只有1100亿投在核高基上。大家这么想一下，核高基投入不足，也就形成我们的短板。”</p>
<figure data-type="image" tabindex="1"><img src="https://yeolar.github.io/post-images/1605489576328.jpg" alt="" loading="lazy"></figure>
<p>以下是黄奇帆11月13日在 “2020中国未来独角兽高峰论坛 ”演讲全全文整理：</p>
<p>两周前，十九届五中全会刚刚闭幕，审议通过了关于制定国民经济和社会发展<strong>第十四个五年计划规划和2035年远景目标的建议</strong>。</p>
<p>这是在新的历史起点上、新的内外形势下，开启新的伟大征程、构建新的发展格局的一次盛会，必将对中国未来 30 年发展轨迹产生深远影响。</p>
<p>今天，我们借这个机会，结合独角兽发展这一会议主题，我想就学习十九届五中全会，加强自立自强有关创新的精神谈一点体会，供大家参考。</p>
<p><strong>中美独角兽企业占全球数量的80%</strong></p>
<p><strong>培育独角兽企业成为各级政府产业政策的重要目标</strong></p>
<p>在胡润2020年全球独角兽榜上显示，今年全球一共有586家独角兽企业上榜，比去年增加了92家，中国和美国占据全球独角兽数量的80% 。</p>
<p>美国有233家，比2019年的203家，增加了30家，中国今年有227家，比2019年的206家增加了21家；</p>
<p>美国估值超过100亿美元的超级独角兽有11家，市值加起来比日本的GDP的6万亿美元还要大。</p>
<p>从区域来看，美国硅谷有122家，占全球独角兽企业的21% ．中国的北京、上海、深圳等地，是独角兽出没相对较多的地区。</p>
<p>正是由于独角兽企业在加速全产业链裂变和迭代方面的特殊作用，培育独角兽企业也成为各级政府产业政策的重要目标 。</p>
<p>国内像南京、武汉、杭州等地，都把培育独角兽作为政府推动创新、促进发展的重要工程来抓。</p>
<p>今天，我们在山西太原召开以独角兽为主题的会议，也体现了山西省委省政府、太原市委市政府抢抓独角兽发展机遇的战略意图，是新形势下贯彻落实总书记关于构建新发展格局战略思想的重要体现。</p>
<p><strong>独角兽的出现与新的风口是分不开的</strong></p>
<p>新一轮科技革命和产业变革浪潮下，产业互联网是新风口，将会出现新的独角兽。独角兽的企业概念，虽然是近10来年提出来的，但这个现象本身早已存在。</p>
<p>事实上，我们回顾经济史，每一个时代的风口都会催生一批独角兽，工业产品的风口，所谓的一个个时代，大体上可以用20年划一个时代。</p>
<p>比如六七十年代，全世界千家万户都使用的商品，实际上就4个，即使中国人说的，收音机、自行车、手表、缝纫机 。</p>
<p>这些在美国，四五十年代就开始进入家庭，日本是五六十年代进入家庭，中国是六七十年。</p>
<p>这个时候，哪个城市能够做这4大件，哪个城市有做自行车或者做手表的企业，这些企业往往是当时最风云、最有名气的，最有广告效应的企业。</p>
<p>在中国来说，到了八九十年代，四大件还照样是老百姓生活需要，但已经不是引领风尚的了。八九十年代的4大件就是空调、洗衣机、冰箱和电视机。</p>
<p>那时候北京、上海、广州、天津能够做这些4大件的，都是属于中国工业最发达的地方。</p>
<p>到了新世纪的20年，进入家庭的四大件，那就是轿车、笔记本电脑、手机、液晶面板形成的各种显示设备 。</p>
<p>哪个城市能够有这4大件的大批量生产企业，哪个城市工业一定比较强，哪个城市有这样的企业，这个企业往往也是中国比较有名气的，或者甚至世界范围内比较有地位的企业，所以这个又是新的时代。</p>
<p>最近这10年，实际上就出现了互联网消费时代的企业，比如阿里巴巴、腾讯、百度，美团等等。</p>
<p>我讲这个概念就是说，每个时代总会有一批企业跟千家万户的生活融合在一起，这种产品需求量规模巨大，谁能在这样的一个巨大的产品需求和产业链当中崛起，成为主体的企业，一般都会成为世界级的大企业。</p>
<p><strong>不同于消费互联网</strong></p>
<p><strong>产业互联网更像是一个行业一个行业的“小锅菜”</strong></p>
<p>今天，我们正处于新一轮科技和产业革命蓬勃兴起、数字经济风起云涌的新时代，在新基建的加持下，产业互联网加是一个风口，一定会催生出体量更大、影响更广的独角兽企业。</p>
<p>所谓产业互联网也就是利用数字技术，把产业各要素、各环节全部数字化、网络化，推动业务流程生产方式的变革重组，进而形成新的产业协作、资源配置和价值创造体系，与消费互联网相比，产业互联网有明显的区别。</p>
<p>比如，产业互联网是产业链集群中多方协作共赢，消费互联网是赢者通吃，产业互联网的价值链更复杂、链条更长，消费互联网集中度较高 ；</p>
<p>产业互联网的盈利模式是为产业创造价值、提高效率、节省开支，消费互联网盈利通常是先烧钱补贴，打败同行对手，再通过规模经济或增值业务赚钱。</p>
<p>这个意思就是，产业互联网实际上在发展中，实际是一个行业一个行业的“小锅菜”。</p>
<p>比如汽车产业链，上千个零部件企业，就是一个行业“小锅菜”，就可能使得不增加投入、不增加原材料消耗的背景下，为产业链增长提供1%~10%的新增值。</p>
<p>也就是说，如果这个产业链原来有1万亿的产出，由于数字化平台的赋能，使得产业链增加额外增加5~10%，变成10，500 亿或者11，000亿，新增的500、1000亿，既是产值也是利润，也是增加值，总之是一个很好的产出的链。</p>
<p>但这个链做完以后，你要像消费互联网一样，1000万人，10亿人、50亿人一刀切的模式推开，是不行的 。</p>
<p>因为汽车产业链有汽车产业链的工业互联网的信息构架，如果到医疗产品的产业链，它的产业链的构架同样是产业链的泛在信息，有各种人工智能分析的信息，这里的结构、内在的含义是完全不同的。</p>
<p>也就是说，你在汽车产业链上发明创造的一些数字技术，不一定在医疗体系的产业链能够直截了当的应用。</p>
<p>从这个意义上，产业互联网这个菜，是要一锅一锅的炒 。</p>
<p>100个工业产业链，可能会有100种工业互联网的摆布结构，你不能一刀切，排浪式的推开，这个是工业互联网跟消费互联网的不同点。</p>
<p>因为人的个性都一样，所以14亿人可以一刀切，一种网络平台，在这样的网络平台下，打败同行变成最重要的了 。</p>
<p>一旦把同行打败了，它就具有了某种垄断的程度，有了垄断的地位，这个时候广告都集中到你这个平台上来了，你就可以收到巨额的广告费。</p>
<p>同样，消费互联网的平台入门费，实际上到了垄断的时候，可能会达到 10%-20% 营业额的费用率，这是很高的 。</p>
<p>我们平时到一个超市、一个百货商店，因为它是个房地产，有物业的成本，这种成本使得你商品上架可能要销售额的15%-20% 。</p>
<p>现在到具有一定垄断意义的互联网消费平台，千家万户的工商企业要把自己的商品上架，特别是能够推到网络页面的前面，就需要付比较高的平台入门费，这都是垄断以后产生的效益。</p>
<p>没垄断的时候，在烧钱竞争的时候，可能是2年、3年、5年，整个过程就是赔本，就是用股东的钱，多少年都赚不了钱。</p>
<p>但是产业互联网不能这么干，产业互联网是在为上千个小企业或者一群龙头企业服务，如果整个的活动过程中，两年、三年对小企业、对龙头企业、毫无帮助、毫无效益，你自己也在烧钱，而别人并没有跟你垄断性市场份额的竞争，大家各管各的。</p>
<p>你做汽车，我做化工，你做机电工业，我做手工业、消费品工业，大家行当不同，也不存在过分的竞争。</p>
<p>你自己烧了许多本钱，又没有给你服务的企业带来具体的好处，你这个企业是没有生存能力的。</p>
<p>就像猪八戒网，它是一个产业互联网，这个产业互联网上现在有5个门类各种各样的企业，如果猪八戒网不能为这5个门类、几十万个企业带来每天看得见摸得着的市场效应、服务效率提高或者各种成本下降的好处，猪八戒网一天都生存不了。</p>
<p>所以搞产业互联网的思维模式，要摒弃消费互联网的发展模式，在消费互联网成功的那一套，产业互联网不一定会成功，这方面大家要有认识。</p>
<p><strong>如果数字化转型能拓展10%的产业价值空间</strong></p>
<p><strong>每年就能多创造2000亿美元的价值</strong></p>
<p>产业互联网是一片蓝色的海洋，它的市场空间有多大呢？</p>
<p>有关材料分析，目前全球有60多个、万亿美元级的产业集群，可以和数字化结合，实现数字化转型。</p>
<p>根据测算，仅仅在航空、电力、医疗、保健、铁路、油气这 个领域，如果引入数字化平台支持，假设只提高1%的效率，全球在未来的15年中可以预计节约近300亿美元 ；</p>
<p>平均每年产生约200亿美元的效益，如果数字化转型能拓展10%的产业价值空间，每年就可以多创造2000亿美元以上的价值。</p>
<p>所以，如果说中国的消费互联网市场目前能够容纳几家万亿级的企业，在产业互联网领域，今后有可能产生或者容纳几十家同等规模的创新企业 。</p>
<p>这是一个巨大的蓝海，今后的独角兽将主要产生于工业互联网的体系。</p>
<p><strong>新基建在全球实际上就是第4次工业革命</strong></p>
<p><strong>中国至少是引领者之一</strong></p>
<p>今年在疫情下，我们党中央3月份的时候提出了一个重要的战略措施，就是推动新基建的发展。</p>
<p>所谓新基建三大工程，第一个叫数字工程，就是5G、大数据、云计算、人工智能、区块链，就是5G加ABCD这5个要素。</p>
<p>数字平台产业化，数字经济产业化，这就是数字工程。这个数字经济产业化，中国在去年的总规模是6万多亿人民币，所以已经有一定规模，但是还不够大，今后加个0都是可能的，这是一个概念。</p>
<p>第二个工程就是产业经济数字化，也就是用数字化综合平台，对产业经济传统产业进行赋能。</p>
<p>我们国家去年工业产业总的销售值是100万亿人民币，这100万亿人民币有上百个各种各样的行业。</p>
<p>有的行业大，有的行业小，这些行业作为传统工业，一旦有数字经济赋能，就会产生颠覆性的资源优化配置的功能，增长1%~10%。这个时候如果用5%来算，100万亿的5%就5万亿，所以后边形成的价值是非常大的。</p>
<p>除了工业以外，还有商业零售，各种各样的服务业，消费类的、贸易类的等等，都有一个数字经济进行赋能的概念。</p>
<p>第三个工程，利用数字经济进行创新工程，推动生物医药和数字经济，以及各种智能制造、关键性的高科技技术、基础创新。</p>
<p>中央说的这三大工程，数字工程、融合工程、创新工程，形成了我们的新基建。</p>
<p>在我们中国叫新基建，在全球实际上就是第4次工业革命。</p>
<p>在第一次工业革命的时代，200多年前，人类进入了机械化蒸汽机时代。那个时候我们正在清朝的后期，整个社会是个封闭体系，所以在第一次工业革命的八九十年过程中，我们国家基本没有受益，也没有得到发展。</p>
<p>第二次工业革命是所谓电气化，也就内燃机、汽车发动机这一类的机械化时代，这个时代差不多也是八九十年，在100多年前，我们正处在清朝末年辛亥革命，国内进行了军阀混战。</p>
<p>再跟着是十几年的抗日战争和4年多的解放战争，所以整个清朝末年到1950年，差不多100年，我们都在打仗之中。</p>
<p>第二次工业革命中国基本上也没跟上，由此形成了中国积弱积贫，落后于世界的这种状态。</p>
<p>解放以后，1950年以后到1980年，我们国家30年的经济发展，尽管计划经济和相对封闭的经济运行状态，但是我们恶补了第一次工业革命和第二次工业革命的欠账。</p>
<p>第三次工业革命是一个信息高速公路、计算机的革命，这个阶段我们进入了改革开放时代，完全跟进了这一场工业革命，以至于现在中国工业成了世界第一大的工业体，同时也是工业门类最为齐全、全要素产业链的工业体系。</p>
<p>但是第三次工业革命我们是跟进者，不是引领者。</p>
<p>现在发生的第四次工业革命，是人类智能化的革命，这个智能化革命时代，以5G为基础的大数据、云计算、人工智能，包括区块链在内的数字革命，也包括生物工程等等。</p>
<p>所有这些，我们不仅是跟进者，我们中国也会是引领者，至少是引领者之一，跟美国、欧洲、日本等等国家一起引领第四次工业革命。</p>
<p>所以这将是人类百年未遇之大变局的一个机遇，人类将从第四次工业革命过程中化解过去几十年积累的欠账坏账，各种各样的要淘汰的东西，走出困境，走上一个新的发展道路。</p>
<p>在这个过程中，我们国家用新基建来引领、推动第四次工业革命，一定能抓住第四次工业革命的战略机遇，在百年未遇之大变局中发挥重大作用。</p>
<p>所以在这个意义上，新基建就是我们时代的风口，而今后二三十年，很多独角兽就将在这个新基建的范围内发生、发育、成长、壮大。</p>
<p>而新基建的核心体系，将不再是消费互联网，而是产业互联网，也就是5g引领下的产业互联网。</p>
<p>这是我要讲的第二部分，就是独角兽的发展要迎着风口去发展，最重要的当下就是新基建、数字化经济、产业互联网、生物医药、各种智能制造、新材料等等。</p>
<p><strong>打通创新链条是培育独角兽的关键</strong></p>
<p><strong>创新的第一个阶段：0到1。原始创新</strong></p>
<p>第三，打通创新链条是培育独角兽的关键所在，地方政府应有所为，有所不为。</p>
<p>创新链条主要有三个环节：</p>
<p>一是从无到有，无中生有的创新，实际上是原始创新，是0~1的环节；</p>
<p>二是从科学到技术的转化创新，是将基础原理转化为生产技术专利的创新，是 1~100的阶段；</p>
<p>三是从技术到产品规模化、产业化，甚至资本化，是100~100万的阶段，地方政府在这三个环节都可以大有作为。</p>
<p>第一个阶段是0~1的创新，就是原始创新、基础创新，无中生有的创新，创新需要专业人才，大专院校、科研院所的专家教授进行实验室里的探索。</p>
<p>在这方面，我们国家目前的短板在哪呢？我们研发创新的经费投入，现在世界规模第二，规模不小，但是投入比较分散，集中度不够。</p>
<p>我们国家去年的研发费占GDP的2.2% ， 100万亿的GDP 差不多是2.2万亿的研发费，这个研发费仅次于美国的总量，我们排第二，所以这个量投入不小，但是我们研发费集中度不高。</p>
<p>在世界各国，特别是发达国家，研发费的 20% 左右集中在基础性的、核心的、高科技的研发方面，也就是我们说的核高基。</p>
<p>核高基的意思就是核心的、高科技的、基本面基础性的创新 。比如我们芯片的创新就属于核高基，飞机发动机的创新当然也是核高基。</p>
<p>在这个意义上讲，我们国家去年核高基领域的研发费总投入，仅仅是我们全部研发费的5%，意思就是我们22，000亿的研发费，实际上只有1100亿投在核高基上。</p>
<p>大家这么想一下，核高基投入不足，也就形成我们的短板，我们在工业和各种发展当中，有一些高科技的技术不掌握，容易被别的国家一剑封喉，扼杀我们，遏制我们。</p>
<p>所以美国人这两年对我们芯片或者其他高科技产品的打压，就是利用他们在核高基领域、关键技术领域、高科技领域走在前面，我们比较落后，一旦没有了这些产品，我们许多产业链会断档。</p>
<p>在世界是平的、地球是圆的、什么东西都能买来的外向型经济的感觉下，这些创新好像无所谓，反正缺什么我买什么，而世界上总是互相分工能买来，出现了造船不如买船，买船不如租船，基本上就把创新这一环节给放松了。</p>
<p>这就是外循环体系下，容易考虑引进消化吸收，什么事情碰鼻子就转弯，攻不下来就去买，买买买就想把天下好东西都买来，但是高科技是买不来的，关键的技术是买不来的，靠要要不来的，必须自主创新。</p>
<p>所以我们国家五中全会提出，十四五期间到2035年期间，直到2050年更长远的期间，要走内循环为主、双循环互相补充、互相支持的新格局。</p>
<p>这个新格局内循环为主，自主自立自强的创新就是最重要的内循环，因为所有的创新，一切民族国家的创新都是内循环，外循环就是引进消化吸收。</p>
<p>在这个意义上讲，把创新这件事，特别是核高基的创新加大比重，今后的 5年或者10年把核高基的比重从现在的5%增加到10%、15%、20% 。</p>
<p>我们国家的体制集中力量办大事是应该做得到的，只要认识一到位，就能够把短板补上去，这是一个概念。</p>
<p>所以这将是我们十四五期间一个重要措施，建议有条件的地方集中优势资源出台政策，鼓励所在地区的高等院校、科研院所、大型科技公司、工业企业加大基础研究投入，在未来5年内将核高基领域的基础研究投入占研发费比重，从现在平均的5%提高到15%左右甚至更高，是我们战略的举措。</p>
<p><strong>独角兽是科创企业的主力军</strong></p>
<p><strong>私募基金、风险投资则是市场化选择独角兽的啄木鸟</strong></p>
<p>培育独角兽企业离不开资本市场的支持和配合。除了政府相应的产业引导基金外，应重点发展风险投资和私募股权等股权投资机构。</p>
<p>如果说资本市场是股权投资的战场，独角兽是科创企业的主力军，私募基金、风险投资基金就是市场化选择独角兽的啄木鸟，是金融服务科创经济的关键所在，是培育独角兽企业的催化剂、良师益友。</p>
<p>美国资本市场中各类风险基金和私募基金集聚的资本总量现在大体上有10万亿美元，我们现在注册的私募基金企业近5万个，集聚的资本也就是5万多亿。</p>
<p>这个概念是这样，私募基金几万个，到去年底整体上集聚的资金 13万亿左右，这个13万亿里边有2万亿在股市里边买卖股票，二级市场的投资，但有7万亿左右买债券、买货币基金，相当于存款，没干什么活，有5万亿是股权投资。</p>
<p>也就相当于我们在说的，不管你买的是独角兽的股权，还是各种各样，0<sub>1，100</sub>100万或者1~100各个阶段创新类企业的股权投资。</p>
<p>总之这一块我们现在是5万亿，规模小，杂而散，如何提高股权投资机构的质量和能力，是中国资本市场建设的重要任务。</p>
<p>国外的私募基金、公募基金一般来说50%会投在资本市场、股权市场，还有50%可能是债券市场或者各种各样的货币基金，我们现在的股权投资比重偏小了，所以没有发挥资本市场和一级市场中的股权的功能。</p>
<p>VC和PE等基金上市前是企业股权融资的重要资金来源，在上市过程中和上市后也是一级二级市场的重要资金渠道，是推动股权融资和资本市场发展的重要动力。</p>
<p><strong>很多发明人为什么没发财？</strong></p>
<p><strong>我们的转化不够</strong></p>
<p>另一方面，还要进一步健全高层次科技人才创新、创业的体制机制。</p>
<p>在这方面我们目前也有个短板，这就是为什么我们刚才说在 1~100 的科研成果产业化、孵化的转化过程中，我们效率相对低的原因。</p>
<p>我们每年有上百个国家级的创新发明，或者技术进步一等奖、二等奖、三等奖，国家有 31 个省，每个省也大体会有几十个到一百个（成果奖）。一年下来，我们全国省级以上的成果奖会有上千个，10年就会上万个。</p>
<p>而且我们又规定，凡是有成果，70% 的专利权都给了专家团队发明人。</p>
<p>那为什么10年下来，没看到太多的发明人变成了 500 万 5000万、5个亿、 50 亿的富翁？</p>
<p>他们为什么没发财？并不是政府不兑现，是因为你这个产品没有得到市场的承认，没有在市场中产生10亿、100亿的效益。</p>
<p>你如果有效益了，这效益的70%，利润的70%就是归你的，但你如果不产生效益，那70%、50%的专利权等于0。</p>
<p>在这个意义上，我们的转化不够，但转换不能够靠发明人去转化。</p>
<p>我们有许多地方搞孵化器，把得到了技术进步一等奖、二等奖的原始发明人、专家拉到孵化器里来搞发明，这是不对的，这是拿大炮打蚊子。</p>
<p>发明人智商很高，能钻牛角尖，能够攻占最复杂的高科技，但是转化的时候要情商，要有广泛的其他的知识，不一定就能做好转化。</p>
<p><strong>推动建设一批科学技术转移机构</strong></p>
<p><strong>提高转化效率</strong></p>
<p>所以在这方面我们缺少两个环节的东西。</p>
<p>第一个，党中央在今年 4 月份关于要素市场进一步市场化改革的决定当中，讲到了五大要素市场，就是劳动力、土地、资本市场、技术市场和数据市场。</p>
<p>讲到技术市场的时候，中央提出在中国要建设推动一批德国的弗劳恩霍夫研究所。</p>
<p>中央文件推荐要建某一种研究所，大家以前很少看到，到底什么是弗劳恩霍夫研究所呢？其实它就是一个科学技术转移机构。</p>
<p>这个研究所并不搞科研创新活动，他所有的工作人员就是科学技术的经纪人，研究所的功能主要特征就是我们中国人说的 婚姻介绍所”，做红娘的。</p>
<p>这个研究所往往把科研院所的知识产权专利，把专利内涵、专利的特性、专利有可能应用的场景把它弄清了、弄透了，然后用科普的方式介绍给社会上相关的，有兴趣的人。</p>
<p>有兴趣的人看到了这个产品可能我没兴趣，那个产品我可能有能力进行转化，他（研究所）就做了个红娘，把善于做转化的人和有技术专利的人进行结合，结合以后，从 1 到 100 转化。</p>
<p>转化成功，他就拥有 0~1 发明者 50% 的知识产权，最后的知识产权是50对50。</p>
<p>如果说发明人有70% ，那转化人就分享35%，形成这么个格局。</p>
<p>这个概念跟硅谷的拜杜法案基本一致， 拜杜法案在几十年前产生，当时这个法律规定，任何美国的科学技术发明1/3 归知识产权投资的，不管是政府投资，还是学校投资，还是科研院所投资，还是科学院投资，还是企业投资，投资者占1/3 。发明人占1/3，把发明转化为生产力的人，他也占1/3 ，这样三个的1/3 。</p>
<p>由于有了这个概念，硅谷可以说有了上百栋各种各样的别墅小楼，一个个里边都是搞转化的。这里边搞转化的，成千上万个各种各样的公司往往不是科学技术的发明人，发明人在斯坦福，在麻省理工学院，在美国几千个大学研究所。</p>
<p>发明以后，他们的菜单提供给了想搞转化的人，转化的人在学校里看着菜单，签个合同，背着书包进去，背着钱包出来，一谈成功，1/3 的知识产权归他。</p>
<p>有了物质刺激，财务的刺激，就有千百万转化的人去干这个活，他如果三年没干成，比如没转换，那他挂在他的墙上也没什么损失。白干三年他也拉倒，也没什么吃亏，在这个意义上，拜杜法案跟弗劳恩霍夫研究所起着相同的功能。</p>
<p>前不久，美国人搞过一次法律研究的评价的会，这100年里边对美国经济社会发展、技术发展最具贡献的法律，拜杜法案就是其中之一。</p>
<p>所以大家可以看到，实际上在独角兽培养过程中，也是要有非常重要的，对专家学者的物质刺激、激励的因素，这种激励不仅是原始创新发明人的激励，也表现为转化者的激励。</p>
<p>独角兽企业如果一半的股权归了转化者，这个转化者可能是技术专利变成生产力的转化者，也包括转化过程中进行企业运行的，市场模式创新的转化者等等。</p>
<p>总之，如果我们能够把这方面的技术，市场体制、机制都改革好，配套好；宏观上有好的国际化、法制化、市场化的营商环境；体制上能够对发明创造的技术转化和市场化、变成独角兽上市也有不同阶段的体制、机制的创新配套，那么我们中国的人才机制，独角兽的发展机制就能真正到位。</p>
<p>各位来宾，创新是企业经济发展的不竭动力，“十四五”时期要实现创新能力显著提升，需要有一批引领科技革命和产业变革的独角兽。</p>
<p>让我们拭目以待，迎接独角兽成群结队的奔腾而来，谢谢。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[比特币起源发展史]]></title>
        <id>https://yeolar.github.io/post/bi-te-bi-qi-yuan-fa-zhan-shi/</id>
        <link href="https://yeolar.github.io/post/bi-te-bi-qi-yuan-fa-zhan-shi/">
        </link>
        <updated>2020-11-15T13:30:01.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-什么是比特币">1、什么是比特币</h1>
<p>比特币，英文名BitCoin，简称BTC，是一种由开源的P2P软件产生的电子货币，是一种网络虚拟货币。比特币不依靠特定货币机构发行，它通过特定算法的大量计算产生，比特币经济使用整个P2P网络中众多节点构成的分布式数据库来确认并记录所有的交易行为。P2P的去中心化特性与算法本身可以确保无法通过大量制造比特币来人为操控币值。</p>
<p>比特币（BTC）是基于密码学、依托于区块链技术的一种去中心化传输模式的加密货币。目前在加密货币市场中市值排名第一。</p>
<p>您可以访问比特币历史网站看看比特币的价格：http://history.btc126.com</p>
<h1 id="2-比特币的起源">2、比特币的起源</h1>
<p>2008年，美国金融危机爆发，引发了全球经济危机。这场风暴早期出现在美国次级房屋信贷市场，大批借贷者无法按时还款，逐步引起流动性危机。加上美国政府为了缓解危机大量发行美元救市，更加暴露出中心化模式的致命缺点：由于交易双方之间缺乏信任，往往需要中心化机构进行担保，但这并不能保证双方都会履约，或者中心机构一定能发挥正面作用。</p>
<p>2008年11月1日，中本聪（Satoshi Nakamoto）发布比特币白皮书，详细阐述了比特币的运行机制。比特币运用区块链技术建立了一个基于加密技术的去中心化支付系统，解决了交易信任问题。该系统通过使用工作量证明机制和点对点网络对公开的交易进行记录，交易双方在不需要第三方机构的情况下，也能正常进行比特币交易。</p>
<p>2009年1月3日，比特币区块链的创世区块被中本聪挖出，并产生了50个BTC的区块奖励，标志着比特币的正式问世。</p>
<p>2009年1月12日，Hal Finney从中本聪处获得10个BTC，由此产生了第一笔比特币转账交易。</p>
<h1 id="3-比特币的运行机制">3、比特币的运行机制</h1>
<p>每一笔比特币交易，都会被区块链网络中的节点记录下来，以此增强交易公信力，保护交易双方利益。但如果所有节点都参与记录的话，容易因为网络延迟等因素造成账本信息不一致，也难以避免记账人会篡改交易信息。</p>
<p>因此比特币采用工作量证明（Proof of Work）共识机制，让所有节点通过解决工作量证明难题的方式参与竞争，竞争成功的节点拥有新区块的记账权，并能够将记录的信息广播出去。其他节点接收后将根据此消息进行数据同步，确保账本一致。这种竞争记账权的过程，叫做挖矿，参与挖矿的节点，叫做矿工。矿工挖矿成功后可以获得区块奖励，即一定数额的比特币，还可以收取该区块上的交易手续费。在利益的驱使下，节点会积极参与挖矿并维护交易记录的真实有效。</p>
<p>比特币的发行只有一种方式，即区块奖励，也就是说比特币是通过挖矿产生的。不过，比特币并不能通过挖矿无限产生，其算法规定了每产生210,100 个区块（约四年），比特币的区块链奖励就要减半一次。由于比特币的发行总量恒定为2100万个，预计会在2140年挖完。这个规定确保了比特币不会由于人为增发而发生严重的通货膨胀，可以保护比特币的价值。</p>
<h1 id="4-比特币与区块链的渊源">4、比特币与区块链的渊源</h1>
<p>比特币的运行以区块链技术为依托，比特币与区块链有着密不可分的关系。比特币是一种资产，而区块链就是为这种资产设定好运行规则的底层技术，从而保证每一笔交易顺利进行。这就好比视频文件与播放器之间的关系，视频的播放必须要通过播放器的底层技术处理才能实现。区块链技术的诞生源于比特币概念的提出，可以说区块链技术是比特币催化下的产物。目前，区块链技术不止运用于比特币等加密货币，在各个领域都有广泛的应用，但比特币仍旧是区块链技术上最早、最成功的应用。</p>
<h1 id="5-比特币的三个特点">5、比特币的三个特点</h1>
<ol>
<li>去中心化</li>
</ol>
<p>传统的经济模式里，货币由政府机构发行，交易双方的个人基本信息和转账交易等信息都掌握在银行等第三方机构的数据库里，由这些机构集中管理。这些机构掌握的信息资料齐全，能对交易双方做出较为准确的信用评估，以及在出现纠纷后进行公正的仲裁。所以交易双方会在它们的介入和担保后，再进行交易。交易双方只可以查阅与自己相关的数据，这就是中心化的管理模式。</p>
<p>然而，在比特币的去中心化模式里，机构既没有发行比特币的权利，也无权记录和管理用户信息。比特币网络采用分布式记账的方式，保证每一笔交易都被公开记录，并同步到整个区块链中，人人可查。同时，由于比特币区块链采用了特殊的数据结构，以及使用工作量证明进行计算的共识算法，因此保证了区块内交易记录无法被篡改。这种运行模式公信力非常强，不需要第三方机构介入。</p>
<ol start="2">
<li>匿名性</li>
</ol>
<p>比特币采用密码学的方式对个人身份进行确认以及对资产进行加密保护。在比特币区块网络建立一个账户，不需要上传任何有关身份背景的证明资料，只要拥有私钥，就能真正掌控对应地址中的比特币。所有交易都是匿名进行的，其他用户在查询区块交易记录时，只能查询到某一地址向另一地址转账的比特币数量，无法将交易双方锁定为某个具体的人，因此不会泄露个人信息。同时，比特币不受时间和空间限制，可在全球范围内流通，它的流通性是传统货币无法比拟的。</p>
<ol start="3">
<li>自主性高</li>
</ol>
<p>用户的比特币由用户通过私钥进行控制，可以被隔离保存在任何存储介质内，且任何人都不能强制收取费用。用户保管好私钥不泄露代表了其拥有该资产的绝对主权。</p>
<p>总结：比特币的问世具有跨时代的意义。它的诞生颠覆了传统的交易模式，带来了被广泛运用的区块链技术。其他加密货币也在比特币的启发下应运而生，从而开辟了新的投资交易市场。</p>
<h1 id="6-一张图读懂比特币">6、一张图读懂比特币</h1>
<figure data-type="image" tabindex="1"><img src="https://yeolar.github.io/post-images/1605447271615.png" alt="" loading="lazy"></figure>
<h1 id="7-比特币的由来">7、比特币的由来</h1>
<p>2008年，一位称为中本聪(Satoshi Nakamoto)的人发表了一篇新的论文，论文阐述了以密码学为基础的电子货币理论(也就是现在的比特币)。论文指出：世界各国的货币这么多，而每个国家的货币只是一个流通符号，一旦失去了国家的信用保障，它们就是一堆废纸。为什么不发明一套世界通用，而又无国别之分的货币系统呢？于是，论文详细讲述了如何利用密码学制造一种虚拟货币的方法。这就是比特币的理论。</p>
<p>在论文中提出的比特币货币系统，有一些这样的属性：</p>
<p>(1) 去中心化：没有发行人，整个网络由用户构成，采用P2P方式存储和运行<br>
(2) 全世界流通：世界上任意一台电脑，只要下载比特币客户端，就可以制造、出售、购买、收取比特币<br>
(3) 安全持有：操控比特币需要私钥，它可以被隔离保存在任何存储介质。除了用户自己之外无人可以获取。<br>
(4) 低交易费用：可以免费汇出比特币，但最终对每笔交易将收取约0.001比特币的交易费以确保交易更快执行。收取的交易费，会做为奖励，发给后续去制造比特币的用户。<br>
(5) 方便快捷的交易转账：只要你知道对方的账户地址，就可以转账，方便快捷<br>
(6) 防止通货膨胀：全世界一共只产生2100万个比特币，从发布之日起，每10分钟产生50个比特币，但产量每4年会减半，即发布4年后，每10分钟产生25个比特币，发布8年后，每10分钟产生12.5个比特币，这些新产生的比特币，属于制造比特币的人。</p>
<h1 id="8-比特币大事记">8、比特币大事记</h1>
<p>2009年，比特币系统正式发布，但由于知道的人很少，1比特币的价格仅几美分。</p>
<p>2013年4月，随着越来越多的人认可和发现比特币，比特币的价格4年来累计飙升了上万倍，1比特币的价格最高达到了266美元。</p>
<p>2013年11月，比特币价格飙升到1000美元。</p>
<p>2014年，随着央行对比特币的监管，比特币开始走下坡路，但是比特币的相关应用却不断发展壮大。</p>
<p>2015年，2016年，这是沉淀的2年，比特币默默无闻，甚至被遗忘。</p>
<p>2017年9月4日，因为ICO的搅局，中国人民银行等七部委发布的《关于防范代帀发行融资风险的公告》，要求国内交易所于10月底全部关门。</p>
<p>随后，各交易所转战海外，分别开设了国外交易平台，比特币等虚拟货币再次满血回归，价格也不断攀升，最高到12万元/枚。</p>
<p>2018年，比特币没有多大的起伏，N多的区块链媒体平台倒闭，价格始终在2万-2.5万之间徘徊。</p>
<p>2019年，新年开始，比特币开始骚动不安，今年会是比特币疯狂的一年么？</p>
<p>2019年4月1日，比特币价格突然暴涨，一度达到5000美元。</p>
<p>2019年6月20日，比特币价格再度突破1万美元。</p>
<p>2019年10月25日，中共中央政治局提出把区块链作为核心技术自主创新重要突破口，加快推动区块链技术和产业创新发展。</p>
<p>2020年，今年比特币将第三次减半，价格也随之上涨。</p>
<p>2020年2月9日，比特币价格再次突破1万美元。</p>
<p>2020年3月12日，比特币遭遇黑色星期四，从8000美元跌至4860美元。</p>
<p>2020年5月，比特币产量将减半，以历史来看大概率会上涨。</p>
<p>2020年5月12日3时23分 比特币第三次减半完成，产量由12.5个降至6.25个</p>
<p>2020年7月26日 比特币价格再次突破10000美元，牛市即将开启？</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[一张图读懂公司成长发展史]]></title>
        <id>https://yeolar.github.io/post/yi-zhang-tu-du-dong-gong-si-cheng-chang-fa-zhan-shi-airbnbinstagrampinterestangry-bird/</id>
        <link href="https://yeolar.github.io/post/yi-zhang-tu-du-dong-gong-si-cheng-chang-fa-zhan-shi-airbnbinstagrampinterestangry-bird/">
        </link>
        <updated>2020-11-14T11:47:42.000Z</updated>
        <summary type="html"><![CDATA[<p>AirBnB，Instagram，Pinterest，Angry bird 是怎么诞生的？这些创业者都是怎么成功的？让我们先来看一下这些公司的创业历程（图片来自网络）。</p>
<p>好像看起来，这些公司都经历过濒临死亡的边缘。所以，一帆风顺的时候不要沾沾自喜，坎坷崩溃的时候，也不要过度消极，说不定你就是下一个 AirBnB。</p>
]]></summary>
        <content type="html"><![CDATA[<p>AirBnB，Instagram，Pinterest，Angry bird 是怎么诞生的？这些创业者都是怎么成功的？让我们先来看一下这些公司的创业历程（图片来自网络）。</p>
<p>好像看起来，这些公司都经历过濒临死亡的边缘。所以，一帆风顺的时候不要沾沾自喜，坎坷崩溃的时候，也不要过度消极，说不定你就是下一个 AirBnB。</p>
<!-- more -->
<h1 id="三个年轻人如何从-3-张气垫床做到全球-100-万间房">三个年轻人如何从 3 张气垫床做到全球 100 万间房？</h1>
<figure data-type="image" tabindex="1"><img src="https://yeolar.github.io/post-images/1605354894324.jpg" alt="" loading="lazy"></figure>
<p>Airbnb创业过程：旧金山的2个付不起房租的哥们，决定出租他们3个充气床，他们做了个简单的介绍网站，3个人来了每个人付了80美元，2哥们开始觉得这个巨棒的主意，找到前任室友当合伙人，产品上线来了2个订单，几个月后平均每周收入200美元，拿到60万元美金风投，拿到720万美金风投然后拿到1亿美金风投。</p>
<h1 id="pinterest是这么诞生的">Pinterest是这么诞生的？</h1>
<figure data-type="image" tabindex="2"><img src="https://yeolar.github.io/post-images/1605354986491.jpg" alt="" loading="lazy"></figure>
<p>Pinterest创业过程：在GOOGLE里做EXCEL表格做到疯，下班之前做点闲杂项目，跟很多人聊创业想法，女朋友跟他说别叽叽歪歪直接做吧，决定从GOOGLE辞职，没有打计划，在考虑各种想法，找到了个联合创始人，做了个APP叫TOTE失败，找到第三个联合创始人，被几个风投拒绝，怕回GOOGLE丢人坚持干下去，做了50个不同版本，产品上线4个月后200个用户，给7000个不同用户亲自写EMAIL，自己母亲是Pinterest第一个忠实用户，现在2500万用户，全球世界流量排名35。</p>
<h1 id="愤怒的小鸟是这么诞生的">愤怒的小鸟是这么诞生的？</h1>
<figure data-type="image" tabindex="3"><img src="https://yeolar.github.io/post-images/1605354994840.jpg" alt="" loading="lazy"></figure>
<p>愤怒的小鸟创业过程：三个哥们开了一个公司，一起开发了51个游戏，穷的差点破产，决定最后做一个就不做了，在一起想了10个不同想法，其中一个就是愤怒的小鸟。</p>
<h1 id="instagram是这么诞生的">Instagram是这么诞生的？</h1>
<figure data-type="image" tabindex="4"><img src="https://yeolar.github.io/post-images/1605355008121.jpg" alt="" loading="lazy"></figure>
<p>Instagram创业过程：工作下班之后自学编程，做了一个H5的原型叫Burbn，给几个朋友试用，见了几个投资人展示给他们看，决定辞职，拿到50万美元天使投资，找到一个合伙人，做了一个巨难用的版本，决定回到原先的Burbn，决定把除了照片之外的功能全部删除，改名叫Instagram。</p>
<figure data-type="image" tabindex="5"><img src="https://yeolar.github.io/post-images/1605355016536.jpg" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Swiftype为什么从EC2切换到真正的服务器]]></title>
        <id>https://yeolar.github.io/post/swiftype-wei-shi-me-cong-ec2-qie-huan-dao-zhen-zheng-de-fu-wu-qi/</id>
        <link href="https://yeolar.github.io/post/swiftype-wei-shi-me-cong-ec2-qie-huan-dao-zhen-zheng-de-fu-wu-qi/">
        </link>
        <updated>2020-11-14T11:30:27.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://swiftype.com/">Swiftype</a> 是一家搜索解决方案提供商，目前已为超过 10 万个网站和应用程序提供搜索服务。 <a href="https://twitter.com/kovyrin">Oleksiy Kovyrin</a> 是其技术运营部门的负责人。近日，他发表了一篇<a href="http://highscalability.com/blog/2015/3/16/how-and-why-swiftype-moved-from-ec2-to-real-hardware.html">博文</a>，介绍Swiftype 为什么以及如何从EC2 切换到真正的服务器。</p>
]]></summary>
        <content type="html"><![CDATA[<p><a href="https://swiftype.com/">Swiftype</a> 是一家搜索解决方案提供商，目前已为超过 10 万个网站和应用程序提供搜索服务。 <a href="https://twitter.com/kovyrin">Oleksiy Kovyrin</a> 是其技术运营部门的负责人。近日，他发表了一篇<a href="http://highscalability.com/blog/2015/3/16/how-and-why-swiftype-moved-from-ec2-to-real-hardware.html">博文</a>，介绍Swiftype 为什么以及如何从EC2 切换到真正的服务器。</p>
<!-- more -->
<p>2012 年，Swiftype 创建之初选择了 Amazon Web Services 作为基础设施，因为云容易增加服务器，而又不需要自己管理硬件，并且没有前期成本。遗憾地是，虽然有些服务（如 Route53 和 S3）非常有用且稳定，但 EC2 却常常给团队带来困扰。基础设施的可靠性和稳定性决定着他们能否满足客户的性能期望和不间断服务的需求。但在 Amazon 云上，他们经常会遇到网络问题、VM 实例宕机问题、不可预见的性能衰减（可能是由同他们共享硬件的其它应用程序导致的）。这些问题占用了他们大量的时间。因此，他们决定放弃 EC2，转而使用真正的硬件。基于以往与托管供应商打交道的经验，他们决定选择 SoftLayer。</p>
<p>在迁移之前，他们有大约 40 个 Amazon EC2 实例，每周会遇到 2 到 3 次严重的问题，有时候每天都遇到。于是，他们决定切换到真正的硬件，并且切换过程不能中断现有服务。为此，他们从以下两个方面做了充分的准备：</p>
<ul>
<li><strong>连接 EC2 和 SoftLayer</strong>——他们在 SoftLayer 上的数据中心里构建一个新的基础设施架构，即可以以开发级负载运行所有关键生产服务的最小服务器子集。然后，他们在新旧数据中心之间构建了一个 VPN 隧道系统，用于确保两个数据中心的组件之间可以实现透明的网络连接。</li>
<li><strong>修改应用程序架构</strong>——他们对应用程序进行了修改，确保它们可以在原有的云环境和新建的基础设施上并行运行。然后，他们构建了一个数据复制通道，用于确保云基础设施和 SoftLayer 部署能够保持同步。</li>
</ul>
<p>Amazon EC2 的 Virtual Private Cloud（VPC）功能提供了一种连接 EC2 服务器和另一个私有网络的方法。但是，对于 Swiftype 的现有实例而言，他们需要停机才能以这种方式实现连接。在经过慎重地考虑和计划之后，他们意识到，真正需要跨数据中心互连的只有 MongoDB 节点，其它的都可以使用数据中心的本地服务，如 Redis 集群、搜索服务器、应用程序集群等。这样一来，需要互连的实例数量就相对较少了。因此，他们采用了一种简单但经证明稳定且有效的方式：</p>
<ul>
<li>每个数据中心部署一个专用的 OpenVPN 服务器，用于实现所有客户端流量到其私有网络地址的转换；</li>
<li>每个需要连接到另一个数据中心的节点会建立一个 VPN 通道，并建立本地路由表，将所有指向另一个数据中心的连接正确地转发到那个隧道。</li>
</ul>
<p>接下来是修改应用程序架构，这项工作的前提是深入了解每个组件。Kovyrin 指出，对于任意复杂度的基础设施，其迁移都必须有足够的时间和工程师资源，要仔细考虑应用程序和后端服务之间建立的每一个网络连接。该过程主要包含如下步骤：</p>
<ul>
<li>所有无状态服务（缓存、应用程序集群、Web 层）均在两个数据中心单独部署。</li>
<li>对于每个有状态后端服务（数据库、搜索集群、异步队列等），他们必须考虑是否需要将数据复制到另一个数据中心，或者是否不得不承担数据中心互连造成的延迟。总之，VPN 是最后选项，尽量减少数据中心之间的流量和到无法复制的主服务副本的连接。</li>
<li>对于可以复制的服务，他们就复制，并确保应用程序服务器总是或优先使用服务的本地副本。</li>
<li>对于无法复制的服务（如搜索后端），他们修改应用程序，使用异步工作进程和队列实现数据复制。</li>
</ul>
<p>经过一个多月的努力后，一切准备就绪。他们通过将 DNS TTL 调至几秒开启切换。在 EC2 流量已经很少之后，他们停用了旧数据中心，并将剩余的连接转发到新数据中心。由于 DNS 更新需要时间，这个过程持续了至少一个周的时间。</p>
<p>从 EC2 切换到真正的硬件之后，发生了以下几个方面的变化：</p>
<ul>
<li>稳定性提升：严重故障次数由每周 2 到 3 次降到了每月 1 到 2 次；</li>
<li>性能提升：所有后端服务的性能都获得了提升，IO 密集型服务（如数据库和搜索集群）比 CPU 密集型服务提升更明显，更重要的是，性能有了更强的可预见性，不会突然出现与软件活动本身无关的降低或升高；</li>
<li>成本降低：月度成本至少降低了 50%；</li>
<li>配置灵活度提升，但配置时间增加了。</li>
</ul>
<p>最后，Kovyrin 总结道：</p>
<blockquote>
<p>如果你的目标从一开始就是业务构建，并且没有多余的工程师资源消耗在“云税（cloud tax）”上，那么，使用真正的硬件可能是更好的选择。</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Algolia通往高可用搜索API的狂暴之路]]></title>
        <id>https://yeolar.github.io/post/algolia-tong-wang-gao-ke-yong-sou-suo-api-de-kuang-bao-zhi-lu/</id>
        <link href="https://yeolar.github.io/post/algolia-tong-wang-gao-ke-yong-sou-suo-api-de-kuang-bao-zhi-lu/">
        </link>
        <updated>2020-11-14T11:05:43.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="http://www.algolia.com/">Algolia</a> 是一家提供托管式搜索 API 的初创企业。作为一家年轻的企业，其<a href="http://highscalability.com/blog/2015/3/9/the-architecture-of-algolias-distributed-search-network.html">架构</a>令人印象深刻：</p>
<ul>
<li>其高端专用机器托管在世界上 13 个地区的 25 个数据中心里</li>
<li>其 master-master 配置至少会在三台不同的机器上复制他们的搜索引擎</li>
<li>每个月处理超过 60 亿次查询</li>
<li>每个月接收和处理超过 200 亿次写操作</li>
</ul>
]]></summary>
        <content type="html"><![CDATA[<p><a href="http://www.algolia.com/">Algolia</a> 是一家提供托管式搜索 API 的初创企业。作为一家年轻的企业，其<a href="http://highscalability.com/blog/2015/3/9/the-architecture-of-algolias-distributed-search-network.html">架构</a>令人印象深刻：</p>
<ul>
<li>其高端专用机器托管在世界上 13 个地区的 25 个数据中心里</li>
<li>其 master-master 配置至少会在三台不同的机器上复制他们的搜索引擎</li>
<li>每个月处理超过 60 亿次查询</li>
<li>每个月接收和处理超过 200 亿次写操作</li>
</ul>
<!-- more -->
<p><a href="https://www.linkedin.com/in/julienlemoine">Julien Lemoine</a> 是 Algolia 的联合创始人兼首席技术官。他计划用一个系列的文章，介绍他们如何分 15 步构建出如此高可用的基础设施。近日，他发表了这个系列的<a href="http://highscalability.com/blog/2015/7/13/algolias-fury-road-to-a-worldwide-api.html">第一篇文章</a>，重点讨论了前三个步骤。</p>
<p>在开始介绍架构之前，Julien 比较了云和裸机。对于大多数情况而言，云基础设施都是一个不错的方案。它易于部署，而且本身提供了高可用性。而基于裸机的基础设施需要他们自己构建高可用性。但选择裸机基础设施，他们可以购买性能更好的硬件，而且与所获得的性能相比，价格也算相当便宜了。</p>
<p>接下来，Julien 按时间顺序介绍了 Algolia 架构演进的前三个阶段，时间跨度为 2013 年 3 月到 8 月。</p>
<h1 id="步骤12013-年-3-月">步骤1：2013 年 3 月</h1>
<p>这个阶段，他们的搜索服务 API 内测版本开始运行。基于对产品市场前景的自信，他们在两个不同的地点（加拿大东部和欧洲西部）分别部署了一台机器。每台机器根据地点为不同的用户提供服务。此时，他们百分百关注性能，时钟频率是他们决策时重点考虑的一个因素，因为就同一代 CPU 而言，时钟频率与搜索引擎的搜索查询速度有直接关系。索引由单独的进程完成，而且优先级较低；而所有的查询都直接在 nginx 内处理，并且优先级最高，即它可以占用更多的 CPU 时间，这样可以有效地处理流量峰值。让他们引以为豪的是，其中一个内部测试用户执意用 Algolia 的服务替换了其当时正在使用的解决方案。</p>
<h1 id="步骤22013-年-6-月">步骤2：2013 年 6 月</h1>
<p>经过三个月的开发和大量的测试，他们在 Beta 测试中引入了高可用性，其思想是：用集群取代了单机，集群由三台相同的机器组成，每台机器都完美地复制了所有数据，均可以作为 master。也就是说，每台机器都可以接受用户的写操作，每次写操作都会触发一个一致性保证机制。另外，基于前期的测试，他们发现：</p>
<ul>
<li>32G 的内存不够用，单是索引进程有时候就会用掉 10G</li>
<li>磁盘空间不够用，为了处理节点失败，机器需要将多个任务保存在磁盘上</li>
</ul>
<p>由于内存需求增加，他们将机器由 Xeon E3 系列换成了 Xeon E5 系列，因为前者只能处理 32G 内存。而考虑到时钟频率的重要性，他们决定采用 Xeon E5 1600 系列。至此，他们已经提供了高可用性。</p>
<p>与此同时，他们还测试了多种负载均衡和故障检测方法，发现所有的硬件负载均衡器均让他们几乎不可能使用多个提供商。于是，他们在 API 客户端中实现了一种基本的重试策略，即在开发的时候确保每个 API 都能够访问三台不同的机器。</p>
<h1 id="步骤32013-年-8-月">步骤3：2013 年 8 月</h1>
<p>他们将 API 客户端的数量增加到 10 种， 包括 JS、Ruby、Python、PHP、Objective-C、Java、C#、Node.js 等。而且，他们尽量避免自动生成代码，人工开发了 API 客户端。2013 年 8 月，他们在上述两个地点（加拿大东部和欧洲西部）正式推出了其搜索服务 API。每个地点一个集群，每个集群包含三台相同的主机。主机换成了 E5-2687W，内存加倍（128G），并且使用了更好的 SSD。这主要是因为他们观察到，内存不足以缓存所有的用户数据，而 SSD 成为索引速度的瓶颈。接下来，他们又重点实现了“可用区域（availability zone）”。关于这一点，Julien 并未提供细节信息。</p>
<p>在本系列的下一篇文章中，Julien 将介绍其 API 正式推出后前 18 个月的情况以及所有意料之外的问题，其中包括第一次停机。</p>
<hr>
<p>在本系列的上一篇文章中，Algolia 联合创始人兼首席技术官Julien Lemoine 介绍了他们构建高可用基础设施的前3 个步骤。近日，本系列的<a href="http://highscalability.com/blog/2015/7/20/algolias-fury-road-to-a-worldwide-api-steps-part-2.html">第二篇文章</a>发表，主要介绍自2013 年9 月API 正式推出至2014 年12 月18 个月间的情况以及所有意料之外的问题，其中包括第一次停机。</p>
<h1 id="步骤42014-年-1-月部署会危及高可用性">步骤4：2014 年 1 月——部署会危及高可用性</h1>
<p>在这个阶段，他们主要关注如何实现敏捷开发而又不以牺牲稳定性为代价。为此，他们开发了一个测试套件，其中包含6000 多个单元测试和200 多个非回归测试。但还是不够，即使一项新特性通过了所有的测试，仍然可能在生产环境中引入Bug，比如，曾有个Bug 导致了 <a href="https://blog.algolia.com/postmortem-todays-8min-indexing-downtime/">8 分钟的索引操作中断</a>。多亏他们在设计架构时实现了搜索查询与索引操作的分离，前者才没有受到影响。不过，这个问题让他们确定了其高可用设置中的一些问题：</p>
<ul>
<li>回滚要快，为此，他们实现了通过单行命令回滚；</li>
<li>部署脚本需要执行完整性检查，如果有错误，就自动回滚；</li>
<li>不能仅仅因为测试通过就部署到生产环境中的所有集群上，他们会按照顺序依次部署测试集群、社区集群（面向免费用户）、付费用户集群。</li>
</ul>
<p>现在，当有新特性需要测试时，他们会选择一个集群组用于测试，并按照下面的步骤部署：</p>
<ol>
<li>向所选集群组中所有集群的第一台机器部署；</li>
<li>监控 24 小时，然后向所选集群组中所有集群的第二台机器部署；</li>
<li>监控 24 小时，然后向所选集群组中所有集群的第三台机器部署；</li>
<li>几天后，向生产环境中的所有集群部署。</li>
</ol>
<p>通过这种方法，他们可以在几个小时内检测到几乎不可能通过单元测试发现的 Bug。</p>
<h1 id="步骤52014-年-3-月处理高负载的写操作">步骤5：2014 年 3 月——处理高负载的写操作</h1>
<p>他们开始解决一个新问题：延迟。他们位于亚洲的集群延迟过高。为了测试市场反应，他们决定将机器部署在 AWS 上。他们并不愿意这样做，因为即使使用 AWS 提供的最好的 CPU，搜索查询的性能仍然比使用 E5-2687W CPU 低大约 15%。不过，为了缩短测试推出时间，他们这样做了。但是，他们尽量确保不引入对 AWS 的依赖，以便后续可以迁移到其它提供商。</p>
<p>同时，欧洲的客户开始抱怨搜索查询延迟增加。他们很快就发现，那与索引操作大幅飙升有关。这初看起来有些不可思议，因为他们在设计时实现了索引操作和搜索查询的分离，但调查之后他们发现，确保集群间一致性的一致性算法在处理写操作时存在瓶颈。当瓶颈出现时，它会阻塞 HTTP 服务器线程，导致搜索查询等待。为了修复这一问题，他们在一致性操作之前实现了一个队列，由它接收写操作，然后将它们批量发送给一致性操作算法。这样，写操作就不会冻结 HTTP 服务器线程了。此后，他们再也没有遇到集群冻结的情况。</p>
<h1 id="步骤62014-年-4-月网络高可用几乎不可能在一个数据中心里实现">步骤6：2014 年 4 月——网络高可用几乎不可能在一个数据中心里实现</h1>
<p>2014 年 4 月初，他们开始收到用户的抱怨。这些用户来自美国东部，但使用加拿大东部的集群，而美国西部的用户则没有受到影响。原来是一场车祸导致了加拿大和美国东部之间的网络路由路径发生了变化，而新路径的带宽不够，不可避免地出现了数据丢失。他们早先没有考虑这种情况，因此，当这种情况出现时，他们只能联系用户并说明情况。</p>
<p>他们认识到，需要基于多提供商、多数据中心和多网络提供商改进高可用性，实现一种真正的分布式基础设施。</p>
<h1 id="步骤72014-年-7-月首次部署到两个数据中心">步骤7：2014 年 7 月——首次部署到两个数据中心</h1>
<p>他们从最大的客户开始将机器部署到不同的数据中心（相距超过 100 公里）。这两个数据中心为同一个提供商所有。同时，根据先前的经验，他们将硬件进行了升级。虽然 E5-2687W 的 CPU 使用率就未到过 100%，但他们还是升级到了使用下一代 CPU 的 Xeon E5-1650v2。结果，他们的服务性能提高了将近 15%。</p>
<h1 id="步骤82014-年-8-月在美国部署服务">步骤8：2014 年 8 月——在美国部署服务！</h1>
<p>2014 年 8 月，他们在美国东部（弗吉尼亚州）和美国西部（加利福尼亚）通过一个新的提供商推出了服务。根据先前的经验，他们使用了同一提供商（不同的网络设备和电源装置）提供的不同的可用区域，并借助更低的延迟和更高的带宽改进了搜索体验。</p>
<h1 id="步骤92014-年-10-月通过-chef-实现自动化">步骤9：2014 年 10 月——通过 Chef 实现自动化</h1>
<p>随着机器数量不断增加，他们将管理工具改成了 Chef。与使用 Shell 脚本相比，这会节省大量的时间。在配置数以百计的机器时，Chef 非常有用，但也有缺点。他们曾经因为 cookbook 的输入错误而导致部分生产环境的服务器宕机。为了防止这类问题再次出现，他们决定将生产环境使用的 cookbook 分成两个版本：</p>
<ul>
<li>第一个版本为稳定版本，部署到所有集群的第一台和第二台机器上；</li>
<li>第二个版本为生产版本，部署到所有集群的第三台机器上。</li>
</ul>
<p>当修改 cookbook 时，他们首先会将修改应用到生产版本。经过几天的测试后，他们才会将修改应用到稳定版本。</p>
<h1 id="步骤102014-年-12-月dns-是架构中的一个-spof">步骤10：2014 年 12 月——DNS 是架构中的一个 SPoF</h1>
<p>随着时间推移，越来越多的用户抱怨他们的服务时断时续，尤其是在亚洲。通过调查他们发现，使用.io TLD 是问题的原因所在。事实证明，同其它顶级域名（.net、.com 和.org）相比，.io TLD 选播网络中的可选地址更少，导致 DNS 服务器过载。用户有时候会在 DNS 解析时遭遇超时。于是，他们将.io TLD 换成了.net TLD，并换了一个允许他们在 <a href="http://algolia.io/">algolia.io</a> 和 <a href="http://algolia.net/">algolia.net</a> 之间同步的 DNS 提供商，这使他们很容易保持向后兼容。迁移完成后，他们进行了广泛的测试，<a href="https://blog.algolia.com/black-thursday-dns-issueolia.io/">发现了几个对部分客户有影响的问题</a>。DNS 比他们想象的复杂，他们的测试并不全面。</p>
<p>这个问题让他们认识到，唯一的DNS 提供商是一个SPoF（单点故障点），而他们的迁移行为实际上是非常危险的。因此，他们开始着手制定计划，消除架构中的SPoF。</p>
<p>至此，Julien 已经介绍了他们构建高可用基础设施的前10 个步骤（总共15 个）。接下来，他将重点讨论他们引以为豪的DNS 以及如何提升高可用性。</p>
<hr>
<p>在本系列的第一和第二篇文章中，Algolia 联合创始人兼首席技术官Julien Lemoine 分别介绍了他们构建高可用基础设施的前3 个步骤和自2013 年9 月API 正式推出至2014 年12 月18 个月间的情况以及所有意料之外的问题（其中包括第一次停机）。近日，本系列的<a href="http://highscalability.com/blog/2015/7/27/algolias-fury-road-to-a-worldwide-api-part-3.html">第三篇文章</a>发表，主要介绍他们如何从一个“初创企业”的架构转变成一个可以满足大型上市公司需求的架构。</p>
<h1 id="步骤112015-年2-月全球同步的基础设施">步骤11：2015 年2 月——全球同步的基础设施</h1>
<p>这个月，他们实现了自2014 年4 月开始就一直为之努力的目标，“将服务扩展到全球，更好地服务于用户”。他们的网络包含12 个不同的地点：美国东部（弗吉尼亚）、美国西部（加利福尼亚）、澳大利亚、巴西、加拿大、法国、德国、香港、印度、日本、俄罗斯和新加坡。最重要的是，他们推出了“分布式搜索”特性。借助这个特性，用户只需几次点击就可以在他们的网络中选定需要自动复制数据的地点。用户使用的API 保持不变，而查询请求会自动路由到最近的地点。这不仅降低了延迟，还提高了搜索基础设施的可用性。</p>
<p>据Julien 介绍，他们的“分布式搜索网络（Distributed Search Network，DSN）”与CDN（内容分发网络）完全不同。他们不是在每个边缘地点缓存常用查询，而是存储一个包含所有数据的完整副本。边缘地点本身都可以响应任何查询。就是说，如果用户选择了三个接入点（美国东部、德国、新加坡），那么位于德国的接入点会响应欧洲用户的查询，位于新加坡的接入点会响应亚洲用户的查询，而位于美国东部的接入点则会响应美国用户的查询。</p>
<p>为了支持这种变化，他们修改了API 客户端的重试逻辑。客户端会首先指向主机名 <a href="http://appid-dsn.algolia.net/t-3.html">APPID-dsn.algolia.net</a> ，后者会使用 DNS 将客户端请求路由到最近的地点。如果最近的主机不可用，那么为了能够返回下一个最近的地点，DNS 记录会在 1 分钟内删除那台主机。这就是他们将每条记录的 TTL 设为 1 分钟的原因。如果遇到这种故障，那么他们的官方 API 客户端会通过在 <a href="http://appid-1.algolia.net/">APPID-1.algolia.net</a> 、 <a href="http://appid-2.algolia.net/">APPID-2.algolia.net</a> 和 <a href="http://appid-3.algolia.net/">APPID-3.algolia.net</a> 上重试将流量重定向到“主区域（main region）”。他们认为，这种方法可以实现高性能与高可用性的最佳平衡。</p>
<h1 id="步骤122015-年-3-月提高单个地点的高可用性">步骤12：2015 年 3 月——提高单个地点的高可用性</h1>
<p>对于搜索和国际用户而言，分布式搜索网络极大的提高了可用性。而为了提高主区域的可用性，他们将美国的集群分布在两个完全独立的提供商那里：</p>
<ul>
<li>两个位置相近的、不同的数据中心；</li>
<li>三台不同的机器——同以前一样，两台位于一个数据中心的不同的可用区域中，一台位于另一个数据中心；</li>
<li>两个不同的自治系统。</li>
</ul>
<p>这样，他们可以选择将流量路由到另一个提供商。他们在提高单个地点的可用性方面迈进了很大一步。</p>
<h1 id="步骤132015-年-4-月随机出现的文件损坏问题">步骤13：2015 年 4 月——随机出现的文件损坏问题</h1>
<p>这个月，他们开始注意到生产环境中随机出现的文件损坏问题，这是由部分 SSD 的 TRIM 实现中存在 Bug 导致的（具体原因参见<a href="https://blog.algolia.com/when-solid-state-drives-are-not-that-solid/">这里</a>）。这是个棘手的问题，他们花了一个月的时间来跟踪和定位。所幸，他们没有丢失任何客户数据，这主要得益于以下两个方面：</p>
<ul>
<li>他们存储了数据的三个副本；</li>
<li>更重要的是，他们没有复制索引操作的结果，而是在每台机器上重复了用户的操作。这有效避免了问题向其它机器传播。</li>
</ul>
<p>他们没有预见到这种问题，但使用独立的机器是他们能够将问题影响最小化的原因。因此，Julien 强烈建议，任何需要高可用性的系统都要采用这种独立性。</p>
<h1 id="步骤142015-年-5-月引入多个-dns-提供商">步骤14：2015 年 5 月——引入多个 DNS 提供商</h1>
<p>他们选择 <a href="https://nsone.net/">NSONE</a> 作为一个 DNS 提供商，因为该提供商提供了很棒的 DNS API，允许他们通过 API 针对每个用户配置查询的路由方式，并且支持 <a href="http://noops.me/?p=653">edns-client-subnets</a> ，可以提供更准确的地理位置路由。</p>
<p>这里的挑战在于，他们需要引入第二家 DNS 提供商，而又不损失 NSONE 提供的强大功能。他们决定通过修改 API 客户端重试策略的方式引入。所有的 API 客户端都会首先连接 <a href="http://appid-dsn.algolia.net/">APPID-dsn.algolia.net</a> ，如果有问题，它们会在另一个提供商提供的顶级域名上重试。他们选择将 AWS Route 53 作为第二家提供商。如果有任何问题，API 客户端将从 <a href="http://appid-1.algolianet.com/">APPID-1.algolianet.com</a> 、 <a href="http://appid-2.algolianet.com/">APPID-2.algolianet.com</a> 和 <a href="http://appid-3.algolianet.com/">APPID-3.algolianet.com</a> 中随机选择一个重试。这样，他们就在 algolia.net 域上保留了 NSONE 所有的地理位置路由特性，同时引入了第二个提供商在 algolianet.com 域上提供了更高的可用性。</p>
<h1 id="步骤152015-年-7-月每个集群跨三个完全独立的提供商">步骤15：2015 年 7 月——每个集群跨三个完全独立的提供商</h1>
<p>虽然经过了一系列的扩展，但他们的基础设施并不能完全应对所有问题，这主要是因为 Link/Router 丢失数据包和路由泄露。在上个步骤中，他们改进了在美国的部署，构建了跨多个数据中心、多个自治系统和多个上游提供商的集群。不过，索引操作需要三台机器中的两台运行正常方可进行。当使用两个提供商时，如果其中一个宕掉，他们就会无法提供索引服务，但搜索服务仍然可用。正是因为这个原因，他们决定实现跨三个完全独立的提供商的集群。这让他们的基础设施超级冗余，但却同时提供了高可用的搜索和索引服务。</p>
<p>总之，构建高可用的架构是需要时间的。所以，作为初创企业，不用在开始的时候就担心基础设施不够完美。但是，应该尽早考虑如何扩展基础设施，Julien 甚至建议在 Beta 测试之前就开始。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[这家伙单打独斗创建了一个网站，然后卖了1亿美元]]></title>
        <id>https://yeolar.github.io/post/zhe-jia-huo-dan-da-du-dou-chuang-jian-liao-yi-ge-wang-zhan-ran-hou-mai-liao-1-yi-mei-yuan/</id>
        <link href="https://yeolar.github.io/post/zhe-jia-huo-dan-da-du-dou-chuang-jian-liao-yi-ge-wang-zhan-ran-hou-mai-liao-1-yi-mei-yuan/">
        </link>
        <updated>2020-11-03T14:37:46.000Z</updated>
        <summary type="html"><![CDATA[<p>外国网站ViralNova创业者是如何做到光靠一人之力，让网站价值1亿美元的？在个人的创业过程中也遭遇挫折。创始人DeLong最终选择出售网站，并非是网站运营不善，那又是什么原因呢？下文着重介绍DeLong的创业历程。</p>
]]></summary>
        <content type="html"><![CDATA[<p>外国网站ViralNova创业者是如何做到光靠一人之力，让网站价值1亿美元的？在个人的创业过程中也遭遇挫折。创始人DeLong最终选择出售网站，并非是网站运营不善，那又是什么原因呢？下文着重介绍DeLong的创业历程。</p>
<!-- more -->
<p>数字媒体公司Zealot Networks 收购了ViralNova，总估值高达1亿美元。ViralNova是一个类似于 Buzzfeed类型的媒体，其创立者是 Scott DeLong。当然，DeLong创建ViralNova网站背后也有一个有趣的故事。</p>
<p>在很长的一段时间里，ViralNova整个网站的创建运营完全由DeLong和两个自由投稿者完成。在他们的努力下，ViralNova发展到了Buzzfeed一样的规模，据估计每月有一亿的读者，而这是在网站没有任何人投资，也没雇佣任何员工下做到的。</p>
<p>ViralNova网站创立于2013年，在网站的每个页面都投放了谷歌的广告。在8个月内，这样简单的运营方式年收入达到百万美元。ViralNova采用故事化的标题来吸引人的注意，发到社交网上后经常让用户疯转。</p>
<p>文章标题类似于：</p>
<p>“It Might Look Like A Normal Chandelier. But When You Stand Underneath It And Look Up.。.Wow.</p>
<p>This Guy‘s Crazy Idea Started To Make His Wife Nervous. But It Was Worth It， Trust Me.”</p>
<p>ViralNova的发展主要是依赖Facebook，比如， EliteDaily、Upworthy、Distractify等几乎都是在同一时间推出，它们发布的文章在Facebook上广泛传播，网站每个月就会增加数千万的读者。</p>
<p>在过去的一年里，Facebook改变了NewsFeed算法让用户看到更少无关的内容，从而打压那些病毒式网站的推广。很多ViralNova的竞争者因此被扼杀，当然DeLong业务也损失惨重。2014年，他用类似的方法在推特上运行网站。</p>
<p>不过，ViralNova最终的结果可能是最成功的。最近，DailyMail 以5000万美元收购了EliteDaily，Mic也筹集数千万资金，主要由Twitter提供。而Upworthy和Distractify也慢慢落寞了。</p>
<p>ViralNova并不是一直像个领跑者。DeLong也有挫败想要认输的时候。</p>
<p>来自俄亥俄州32岁的DeLong以前就建过不少网站，并售卖掉，看似很有经验，但他却不是一个成熟的CEO。在他20岁的时候做了一个网站，每个月利用谷歌广告获得了500美元的收入，网站建立不久后，他就大学毕业了。</p>
<p>“每当睁开眼睛，我觉得如果我每个月能挣500美元，那么我也可以挣5000美元”DeLong回忆道，他认为在互联网领域是没有止境的。</p>
<p>DeLong建立的下一个网站GodVine做得更为成功，这个网站利用Facebook庞大的女性群体，提供容易让人共鸣振奋的故事内容，成为Alexa排名前1500的网站，后来DeLong把网站卖给了Salem Communications。</p>
<p>ViralNova注定要成为一个更大的版本GodVine，ViralNova发布着病毒式的内容。DeLong在巴塞罗那工作期间倍感无聊，于是创建了ViralNova。后来他搬回俄亥俄州，对于网站的创建速度颇为惊讶。</p>
<p>但是在ViralNova上线后的八个月，2014年1月DeLong发现一个人运营这样的一个网站压力太大。他的网站好似一个空落落的Wordpress，ViralNova有太高的流量，DeLong想要在在网站新增任何一点小内容都会影响流量。尽管DeLong收入净值达到数百万美元，但背后工作力度也很大。每天平均工作16个小时，就连周末也不能休息。于是他很快的精疲力竭，雇佣了代理经纪人寻找网站收购者。</p>
<p>令人意外的是ViralNova的买家并不多，但是想要投资的人却不少。有硅谷的风险投资家提出投资数百万美元，让ViralNova成为实质上的企业，不过DeLong拒绝了。</p>
<p>“我并不想担起招聘的责任，也不想开办公室。我喜欢做自己喜欢的事情，很讨厌压力。”DeLong对BI表示。</p>
<p>纽约企业家 Sean Beckner也试图说服DeLong坚持做下去。Beckner在2014年1月份就了解到DeLong想要出售ViralNova的意愿，并发送邮件给DeLong表示可以收购ViralNova的一部分。根据协议，DeLong可以获得报酬并获得自己想要的工作方式，同时进一步扩展网站业务。经过两个月的协商，两人达成共识。</p>
<p>后来Beckner成为ViralNova的CEO和CFO，而Jeff Geurts则任职副总裁，Shaun Tilford任职CTO。</p>
<p>Tilford构建了定制的CMS，并将团队称为Nova，加入社交数据分析工具，该功能能同时测试两个不同的标题哪个效果会更好。此前与DeLong的一同工作的自由作家Sara Heddleston成为了网站主编，同时聘请了12个作家。此外还聘请了专业的销售团队，ViralNova 每月网站页面浏览量破亿。</p>
<p>现在，ViralNova有22个全职员工，今年有望带来3500万美元收入。公司有可能搬到Zealot Media的加州总部威尼斯。尽管DeLong已承诺会继续在ViralNova工作，不过Zealot Networks很大方，给他的待遇超过他的需求。</p>
<p>当被问及现在是否还要每天连续工作16个小时与否，DeLong回答说：“目前的工作方式好很多，我也有自己的私人生活”。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[一个人，一个网站，5.75亿美元卖掉]]></title>
        <id>https://yeolar.github.io/post/yi-ge-ren-yi-ge-wang-zhan-575-yi-mei-yuan-mai-diao/</id>
        <link href="https://yeolar.github.io/post/yi-ge-ren-yi-ge-wang-zhan-575-yi-mei-yuan-mai-diao/">
        </link>
        <updated>2020-11-03T14:19:54.000Z</updated>
        <summary type="html"><![CDATA[<p>一个人，24岁时写了一个网站， 每天只工作2小时，他还嫌工作量太大。他每天从谷歌广告赚好几万美元，不用合伙人，从来也不融资，一个人掌握100%股权， 36岁时5.75亿美元卖掉公司。</p>
<p>2015年7月14日，婚恋网站Plenty of Fish以5.75亿美元的价格被Match Group收购，他的创始人Markus Frind现年才36岁。网站长期由Markus自己一个人从2003年开始经营，就靠放谷歌广告赚钱。</p>
]]></summary>
        <content type="html"><![CDATA[<p>一个人，24岁时写了一个网站， 每天只工作2小时，他还嫌工作量太大。他每天从谷歌广告赚好几万美元，不用合伙人，从来也不融资，一个人掌握100%股权， 36岁时5.75亿美元卖掉公司。</p>
<p>2015年7月14日，婚恋网站Plenty of Fish以5.75亿美元的价格被Match Group收购，他的创始人Markus Frind现年才36岁。网站长期由Markus自己一个人从2003年开始经营，就靠放谷歌广告赚钱。</p>
<!-- more -->
<p>因为网站太赚钱，又没有什么员工，所以Markus完全不需要合伙人，不需要融资，公司的股权100%属于他一个人。卖掉公司时，没有任何人来分这5.75亿美元，5.75亿美元全部属于他一个人！</p>
<p>这简直就是屌丝一个人创业的楷模。</p>
<p>2008年的时候，Markus告诉《纽约时报》，他的网站一年的净利润是1000万美元。他每周工作10小时，每天只干2小时。但是，他居然跟记者说：这个工作量太大了！</p>
<p>Markus对Business Insider说，当他知道什么是风险投资这种东西的时候，他每年已经有几百万美元的净利润了。所以，他实在不知道该怎么跟风险投资人说，实在不知道该怎么融资。</p>
<p>Markus今年卖掉Plenty of Fish的时候， 网站已经有9000万注册用户了。360万活跃用户。</p>
<figure data-type="image" tabindex="1"><img src="https://yeolar.github.io/post-images/1604413295821.jpg" alt="" loading="lazy"></figure>
<p>Markus说他2003年刚开始想做Plenty of Fish，是因为刚刚学会了一门新出来的计算机语言ASP。为了练练手，以后找工作的时候能证明自己懂ASP，就随手做了Plenty of Fish。结果居然有很多人来网站注册，慢慢就火起来了。等到网站每个月能赚4000美元，差不多能养活他自己的时候，他就辞了工作，靠网站的广告费为生。</p>
<p>Markus觉得他创办和维护Plenty of Fish期间，从来没有出现过任何真正困难。Plenty of Fish上线只建立了几个月的时候， 一天只有几百个访客，但是流量增加很匀速、成长很稳定。所以他可以很明确的预到，接下来的四五个月会有多少访客。然后他就有足够的时间，一个人慢慢提高服务器的性能、改善数据库的结构。Markus对记者说，他最骄傲的事情是： “就靠我一个人，每个月能生成10亿个网页页面”。</p>
<p>Markus每天只工作2个小时。INC采访他的时候，问他每天什么时候他觉得最有意思。他说，早上，因为只有早上2-3个小时我在工作。当被问到，你觉得工作时最有意思的事情是什么时，他的回答是：“去银行，把谷歌广告给我开的面额100万的支票存到进去。”</p>
<p>说到谷歌给Markus开的广告费，不得不把Markus的广告收入明细列出来。就是下图：</p>
<figure data-type="image" tabindex="2"><img src="https://yeolar.github.io/post-images/1604413351211.jpg" alt="" loading="lazy"></figure>
<p>2003年6月，只有493个浏览量，广告收入7.6加拿大元（差不多跟美元等值）；2013年7月，就有了18万多的浏览量，广告收入1千7百多了。慢慢每月稳步递增，道理2004年2月，广告收入已经到了1万2千多了。2004年6月的收入，突破了5万块钱。2005年4月， 月收入突破10万元。</p>
<p>2006年6月，他贴出了一张谷歌广告给他寄来的90万元的支票，相对于每天赚3万块。这个时候，这个网站仍旧还是只有他一个人。而他的竞争对手，一般都至少有600台服务器，至少300名以上的员工。</p>
<figure data-type="image" tabindex="3"><img src="https://yeolar.github.io/post-images/1604413368892.jpg" alt="" loading="lazy"></figure>
<p>在实现了每个月自己一个人都能赚到百万美元的目标之后，又过了一年，到了2007年Markus才有了第一个员工人。到现在， Plenty of Fish每个月已经有了 3.7亿的独立IP和25亿的浏览量，员工仍然只有65个人。</p>
<p>一个人，默默创业（甚至都谈不上创业，只是业余做了个“小”网站）；一个人，默默改善自己的网站；一个人，默默赚钱（直到数钱数到手抽筋）。</p>
<p>这才是创业，才是真正的脚踏实地，才是真正的生意。</p>
<p>Markus是每个白手起家者的楷模。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MongoDB简史]]></title>
        <id>https://yeolar.github.io/post/mongodb-jian-shi/</id>
        <link href="https://yeolar.github.io/post/mongodb-jian-shi/">
        </link>
        <updated>2020-11-03T13:19:28.000Z</updated>
        <summary type="html"><![CDATA[<p>说到现代 Web 应用程序开发，不得不提到 MongoDB。如果你是一名全栈程序员，每天都会跟 MERN 打交道，其中 M 指的就是 MongoDB。MongoDB 开源社区版为大量的 Web 应用程序提供支持。从 2007 年开始，MongoDB 走过了漫长的道路。它是 MongoDB 公司的主要产品，这家公司市值已经超过 100 亿美元。与很多产品一样，在线广告是推动 MongoDB 愿景和发展的关键催化剂。MongoDB 的故事很有趣，在本文中，我将带你一起探索 MongoDB 的发展之旅。</p>
]]></summary>
        <content type="html"><![CDATA[<p>说到现代 Web 应用程序开发，不得不提到 MongoDB。如果你是一名全栈程序员，每天都会跟 MERN 打交道，其中 M 指的就是 MongoDB。MongoDB 开源社区版为大量的 Web 应用程序提供支持。从 2007 年开始，MongoDB 走过了漫长的道路。它是 MongoDB 公司的主要产品，这家公司市值已经超过 100 亿美元。与很多产品一样，在线广告是推动 MongoDB 愿景和发展的关键催化剂。MongoDB 的故事很有趣，在本文中，我将带你一起探索 MongoDB 的发展之旅。</p>
<!-- more -->
<h1 id="开端大型数据库想法的萌芽">开端：大型数据库想法的萌芽</h1>
<p>MongoDB 的故事开始于 2007 年。1995 年，Dwight Merriman 和 Kevin O’Connor 创办了著名的在线广告公司 DoubleClick。不久后，Kevin Ryan 也加入了这个团队 (Dwight 和 Kevin 后来共同创办了 5 家公司——Gilt、10gen、Panther Express、ShopWiki 和 Business Insider)。DoubleClick 很快就大获成功，几年之内，它的广告流量达到了每秒 40 万条。当时的关系型数据库技术还没有预料到会有如此大规模的流量。配备如此规模的关系数据库需要大量的资金和硬件资源。因此，Dwight(他是当时的 CTO) 和他的团队开发了自定义数据库实现来扩展 DoubleClick，以应对流量的激增。</p>
<figure data-type="image" tabindex="1"><img src="https://yeolar.github.io/post-images/1604409691495.png" alt="" loading="lazy"></figure>
<p>2003 年，Eliot Horowitz 在大学毕业之后加入 DoubleClick 的研发部门，成为一名软件工程师。两年后，他离开了 DoubleClick，和 Dwight 一起创办了 ShopWiki。他们都意识到，他们在一次又一次地解决同样的水平伸缩性问题。因此，2007 年，Dwight、Eliot 和 Kevin Ryan 一起创办了一家叫作 10gen 的新公司。10gen 专注于提供一个带有自有应用程序和数据库栈的 PaaS 托管解决方案。10gen 很快引起了风险投资人 Albert Wenger(Union Square Ventures) 的注意，他向 10gen 投资了 150 万美元。以下是 Albert Wenger 在 2008 年写的有关 10gen 投资的文字：</p>
<blockquote>
<p>今天，我们很高兴地宣布，我们将为一支特立独行的团队提供支持，也就是 10gen 的一班天才们。他们汇聚了构建互联网规模系统的经验，比如 DART、Panther Express CDN，广泛参与了开源活动，包括 Apache 软件基金会。他们正在为云计算构建一个开源技术栈，包括一个应用服务器和一个数据库，它们都是基于现代硬件能力和构建 Web 站点或服务的经验从头开始开发的。应用服务器最初支持服务器端 JavaScript 和 Ruby(实验性的)。数据库采用了一种有趣的设计来存储对象，这种设计在快速随机访问和高效的集合扫描之间做出了平衡。</p>
</blockquote>
<p>Albert 所说的“采用了有趣的设计的数据库”实际上指的就是 MongoDB。从 2007 年到 2009 年，这个新数据库迅速发展。Dwight 第一次提交的 MongoDB 代码可以在<a href="https://github.com/mongodb/mongo/commit/e73188b5512c82290a4070af4afddac20d0b981e">这里看到</a>。</p>
<p>MongoDB 的核心引擎是用 C++ 开发的。之所以把这个数据库叫作 MongoDB，是因为他们想用它来为一些典型的应用场景 (如内容服务) 提供海量数据的存储服务。最初，这个团队只有 4 名工程师 (包括 Dwight 和 Eliot)，并只专注于 MongoDB 数据库。他们的商业理念是通过开源免费下载的方式来发布数据库，并在这个基础上提供商业支持和培训服务。</p>
<p>MongoDB 1.0 于 2009 年 2 月发布。最初的版本提供了一种具有文档模型、索引和基本复制功能的查询语言，还提供了实验版的分片功能，但生产版本的分片集群功能在一年后发布的 1.6 版本中才有。</p>
<p>以下是 Dwight 对于“Mongo 是否适用于高度可伸缩系统”的问题的回答：</p>
<blockquote>
<p>在水平伸缩方面，可以使用自动分片功能来构建大型的 MongoDB 集群。现在是 alpha 版，但如果你的项目才刚刚启动，那么当你需要它的时候，它可能已经生产就绪了。</p>
</blockquote>
<h1 id="mongodb-早期的设计哲学">MongoDB 早期的设计哲学</h1>
<p>在早期，MongoDB 的基本设计原则如下：</p>
<ul>
<li>快速和简单的数据模型，实现更快的编程——支持 CRUD 的文档模型。</li>
<li>使用熟悉的编程语言和格式——JavaScript/JSON。</li>
<li>无模式文档——方便敏捷迭代开发。</li>
<li>为了快速开发和更易于伸缩，只提供必要的功能，没有连接和跨集合的事务。</li>
<li>支持简单的水平伸缩和持久性 / 可用性 (复制 / 分片)。</li>
</ul>
<p>在 2011 年的一次“NoSQL 以及为什么我们要开发 MongoDB”的 <a href="https://youtu.be/hOOQJpGu1kY?t=2408">ZendCon 演讲</a>中，Dwight 详细介绍了这些原则。大约在 42 分钟的时候，还出现了一个有关复制和分片之间区别的讨论。随着代码的成熟和 MongoDB 成为主流，这些原则当中有很多都被明显淡化了。最新的 MongoDB（从 4.2 开始）可以在一定程度上支持连接，甚至是支持分布式事务！</p>
<h1 id="什么是-mongodb">什么是 MongoDB？</h1>
<p>在详细讲述 MongoDB 的历史和发展历程之前，我们先简单地了解一下 MongoDB！</p>
<p>MongoDB 是一个基于文档的 NoSQL 数据库。它可以在所有主流平台上运行 (Windows、Linux、Mac)，并且可以免费下载它的开源版本。MongoDB 将数据实体存储在集合中，存储的每一个数据块都是 JSON 格式。例如，如果一个用户提交了一个在线订单，该订单的全部细节 (订单号、订单项、收获地址等) 将保存在一个 JSON 文档中，然后将其保存到“customer_order”集合中。</p>
<p>MongoDB 还附带了一个控制台客户端，这是一个功能齐全的 JavaScript 环境，你可以用它添加、删除、编辑或查询数据库中的文档数据。</p>
<h1 id="mongodb-架构">MongoDB 架构</h1>
<p>下面是 MongoDB 服务器主要组件的架构视图。</p>
<figure data-type="image" tabindex="2"><img src="https://yeolar.github.io/post-images/1604410079716.png" alt="" loading="lazy"></figure>
<p>MongoDB 目前为 13 种编程语言提供了驱动程序，包括 Java、Node.JS、Python、PHP 和 Swift。存储引擎 MMAPv1 从 4.2 版本开始就被移除了。加密存储引擎只在商业版中提供。</p>
<p>MongoDB 的美妙之处在于它的开源免费社区版为你提供了这些能力：</p>
<ul>
<li>一个简单的单机实例就可以满足大多数小型应用程序的需求。</li>
<li>一个多机实例可以为大多数商业应用程序提供持久性 / 高可用性。</li>
<li>一个具有水平伸缩能力的大型集群 (分片集群) 可以处理非常大的数据集和大量的查询。MongoDB 提供了自动化基础设施，用于实现分布式的数据分布和处理。</li>
</ul>
<p>下面的这些图表演示了各种运行 MongoDB 实例的方式。</p>
<h1 id="单服务器-容错设置">单服务器 / 容错设置</h1>
<p>对于小型应用程序，单台服务器就足以满足频繁的数据备份需求了。如果需要容错，可以使用副本集。在容错配置中，通常有 3 个或更多的 MongoDB 实例。这些实例当中只有一个作为主实例，如果它发生故障，其他两个辅助实例中的一个将成为主实例。这些实例中的数据都是一样的。</p>
<figure data-type="image" tabindex="3"><img src="https://yeolar.github.io/post-images/1604410167501.png" alt="" loading="lazy"></figure>
<h1 id="具有水平伸缩能力的分片集群">具有水平伸缩能力的分片集群</h1>
<p>对于同时要求具备水平伸缩能力和容错能力的大型数据库，需要使用 MongoDB 分片集群。从下图可以看出，一个容错分片集群推荐的最小机器数量是 14 台！每一个容错副本集只处理数据的一个子集，数据分区是由 MongoDB 引擎自动完成的。</p>
<figure data-type="image" tabindex="4"><img src="https://yeolar.github.io/post-images/1604410301598.png" alt="" loading="lazy"></figure>
<p>在下载最新版本的 MongoDB(4.4) 并解压缩之后，你会发现它只包含以下三个主要文件：</p>
<ul>
<li>mongo——MongoDB Shell，使用基于 JavaScript 的命令与服务器发生交互。</li>
<li>mongod——运行 MongoDB 的主文件，可以作为单个数据库实例、分片集群的成员或分片集群的配置服务器运行。</li>
<li>mongos——一个路由器应用程序，用在具有水平伸缩能力的数据库服务器集群中。</li>
</ul>
<p>在 Mac 上，这 3 个可执行文件的总大小约为 150MB。对于任意类型的 MongoDB 部署，都只需要这几个组件！在一个软件膨胀的世界里，这是一种很受欢迎的变革！这种简单和优雅让 MongoDB 变得强大而可靠。</p>
<h1 id="mongodb-的演化史-2009-年2020-年">MongoDB 的演化史 (2009 年——2020 年)</h1>
<p>MongoDB 1.0 是在 2009 年 2 月发布的，提供了大部分基本的查询功能。MongoDB 1.2 是在 2009 年 12 月发布的，引入了 map-reduce，支持大规模数据处理。在看到 MongoDB 的巨大潜力之后，10gen 公司迅速壮大了团队。MongoDB 1.4(2010 年 3 月) 引入了后台索引创建，MongoDB 1.6(2010 年 8 月) 引入了一些主要特性，比如用于水平伸缩的分片、具备自动故障转移能力的副本集以及对 IPv6 的支持。</p>
<figure data-type="image" tabindex="5"><img src="https://yeolar.github.io/post-images/1604410370487.png" alt="" loading="lazy"></figure>
<p>到了 2012 年，10gen 有 100 名员工，公司开始提供 24/7 服务。MongoDB 2.2 版本 (2012 年 8 月) 引入了聚合管道，可以将多个数据处理步骤组合成一个操作链。到了 2013 年，10gen 拥有 250 多名员工和 1000 多名客户。为了挖掘商业潜力，10gen 更名为 MongoDB 公司，专注于数据库产品。MongoDB 2.4 版本 (2013 年 3 月) 在 Mongo Shell 中引入了文本搜索和谷歌的 V8 JS 引擎等增强功能。除了 2.4 之外，还发布了 MongoDB 企业版，提供了监控和安全集成等附加功能。</p>
<p>MongoDB 早期版本的一个主要问题是它用来保存和管理磁盘数据的存储引擎相对较弱。于是，MongoDB 公司进行了第一笔收购，收购了 WiredTiger 公司。这家公司有超级稳定的存储引擎产品 WiredTiger。MongoDB 拿下了这家公司的开发团队和产品，以及首席架构师 Michael Cahill(也是 Berkeley DB 的架构师之一)，让他担任存储工程总监一职。WiredTiger 是一个高效的存储引擎，使用了各种编程技术，如风险指针（hazard pointer）、无锁算法、快速锁存（fast latch）和消息传递，与其他引擎相比，WiredTiger 可以在每个 CPU 内核上执行更多的任务。为了最小化磁盘开销和 I/O，WiredTiger 使用了紧凑的文件格式和压缩（可选）。</p>
<p>MongoDB 的下一个主要版本是 3.0(2015 年 3 月)，其中包含了新的 WiredTiger 存储引擎、可插拔存储引擎 API、增加了 50 个副本集限制和安全改进。同年，Glassdoor 将 MongoDB 公司列为最佳的雇主之一。同年晚些时候又发布了 3.2 版本，支持文档验证、部分索引和一些主要的聚合增强。</p>
<p>2017 年，微软发布了多模型 NoSQL 数据库服务 CosmosDB，作为微软 Azure 云平台的一部分。它提供了与 MongoDB 3.2 的协议兼容性，针对 MongoDB 3.2 的查询也可以在 CosmosDB 上运行，这加快了开发人员采用 CosmosDB 的速度。</p>
<p>截止 2016 年，MongoDB 公司拥有 500 多名员工，数据库的下载量超过 2000 万次。2017 年 10 月，MongoDB 公司上市，市值超过 10 亿美元。MongoDB 3.6 在一个月后 (2017 年 11 月) 发布，为多集合连接查询、变更流和使用 JSON 模式进行文档验证提供了更好的支持。MongoDB 3.6 是微软 Azure CosmosDB 截至 2020 年 8 月能够支持的最新版本。</p>
<figure data-type="image" tabindex="6"><img src="https://yeolar.github.io/post-images/1604410427511.png" alt="" loading="lazy"></figure>
<p>2018 年，MongoDB 公司斥资 6800 万美元收购了 mLab，这是 MongoDB 公司的第二笔收购。当时，mLab 在云端提供 MongoDB 服务 (DBaaS)，并拥有大量的客户。云计算是未来，MongoDB 公司迅速收购并集成了 mLab，将其作为 MongoDB Atlas 云平台的一部分。然后，他们通过改变开源版本的许可条款来限制更多的 DBaaS 竞争者出现！</p>
<p>MongoDB 开源社区版和高级企业版都使用了相同的底层引擎。这意味着任何人都可以使用社区版，然后基于社区版提供付费的云服务。对于 MongoDB 公司来说，它们的云产品 MongoDB Atlas 就多了很多直接竞争者。因此，在 2018 年 10 月，MongoDB 公司将社区版的许可从 GNU AGPLv3 (AGPL) 更改为服务器端公共许可 (SSPL)。许可中有一个条款用来防止未来 SaaS 竞争对手使用 MongoDB 并提供他们自己的 SaaS 版本：</p>
<blockquote>
<p>如果您将本程序的功能或修改版本作为服务提供给第三方，必须将服务源代码通过网络下载的方式免费提供给所有人。</p>
</blockquote>
<p>这是一个由 MongoDB 公司自己提出的许可条款，并声称兼容 OSI。不过，该条款后来在开放源码计划 (OSI) 的审批过程中被撤回，不过开源版本的 MongoDB 仍然采用 SSPL 许可。</p>
<p>到了 2018 年，MongoDB 公司拥有 1000 多名员工。下一个主要版本 MongoDB 4.0(2018 年 6 月) 提供了跨文档事务处理能力。这是一个重要的里程碑，MongoDB 已经为高数据完整性需求做好了准备。</p>
<p>云生态系统在快速增长，不久后，MongoDB 公司意识到他们需要发展成一个成熟的云平台，而不只是提供数据库服务。2019 年，MongoDB 公司进行了第三笔收购，以 3900 万美元收购了云计算移动数据库公司 Realm。有意思的是，MongoDB 最初也是一种 PaaS 托管解决方案，而 12 年之后，它又回到了同样的方向。同年，MongoDB 公司发布了带有分布式事务支持的 MongoDB 4.2。</p>
<p>截至 2020 年 8 月，MongoDB 社区版版本是 4.4。值得注意的是，MongoDB 数据库工具可以单独下载。MongoDB 4.4 包含了一些主要的特性增强，比如多集合联合聚合、复合哈希分片键和对冲读（Hedged Read）/ 镜像读。</p>
<h1 id="现在的-mongodb">现在的 MongoDB</h1>
<p>截至 2020 年，MongoDB 的全球下载量达到了 1.1 亿次。MongoDB 公司目前有 2000 多名员工，有超过 18000 名付费客户，其中有很多客户同时使用 MongoDB Atlas 和 MongoDB 企业版。截至 2020 年 8 月，MongoDB 社区版版本是 4.4。大多数大公司在内部的一些场景中使用社区版。MongoDB 社区版仍然是开源的，除了一些关键特性外，它与 MongoDB 企业版差不多。</p>
<p>MongoDB 企业版 (每个服务器每年的费用在 1 万美元左右) 提供了以下这些附加功能：</p>
<ul>
<li>内存存储引擎——适用于需要快速数据访问而不需要持久存储的场景。</li>
<li>审计——数据库管理员在部署时跟踪系统活动。</li>
<li>身份验证和授权——支持 Kerberos 身份验证和 LDAP 身份验证和授权。</li>
<li>加密——WiredTiger 引擎提供了一个原生加密选项。默认是 AES256，使用 OpenSSL。</li>
</ul>
<p>除了社区版，MongoDB 公司还提供了以下这些产品：</p>
<ul>
<li>MongoDB Database Tools——命令行工具集合，包括导入 / 导出 (mongodump、mongorestore 等) 和诊断工具 (mongostat、mongotop)。</li>
<li>MongoDB 企业服务器——企业版，提供额外的安全和审计功能。</li>
<li>MongoDB Atlas——基于云的 SaaS 版服务器。</li>
<li>Atlas Data Lake——一个基于云的数据湖工具，由 MongoDB 查询语言提供支持，可以通过 MongoDB Atlas 和 AWS S3 查询和分析数据。</li>
<li>Atlas Search——一个基于云的全文搜索引擎，基于 MongoDB Atlas。</li>
<li>MongoDB Realm——一个为移动应用提供后端服务的托管云服务。</li>
<li>MongoDB Charts——一个云工具，用于创建 MongoDB 数据的可视化表示。</li>
<li>MongoDB Compass——可下载的 GUI 工具，用于连接 MongoDB 数据库和查询数据。</li>
<li>MongoDB Ops Manager——用于在自定义基础设施上部署、备份和扩展 MongoDB 的管理平台。</li>
<li>MongoDB Cloud Manager——云版本的 Ops 管理器。</li>
<li>MongoDB Connectors——为其他平台 / 工具提供的用于连接 MongoDB 的驱动程序。</li>
</ul>
<h1 id="前方的道路">前方的道路</h1>
<p>由于在 SSPL 许可方面存在争议，开发者社区中有一些人对 MongoDB 生态系统持谨慎态度。投资者还面临着围绕生态系统创收的压力。如果你把 2008 年版和 2020 年版的 MongoDB 主页放在一起看，这一点就显而易见 (见下图)。MongoDB 社区版下载页面实际上也列出了企业版中才有的特性！</p>
<figure data-type="image" tabindex="7"><img src="https://yeolar.github.io/post-images/1604410797150.png" alt="" loading="lazy"></figure>
<p>另外，MongoDB 公司还面临来自云供应商的激烈竞争。MongoDB 公司面临的主要问题是数据存储只是企业应用程序的一部分，如果没有一个令人信服的全栈云服务，在未来可能很难与云供应商竞争。</p>
<p>Eliot Horowitz (MongoDB 的关键人物) 于 2020 年 7 月离开了公司。尽管他还在担任顾问的角色，但 MongoDB 的产品仍存在一些风险，比如焦点被弱化、减少对免费社区版的支持或进一步修改许可条款。</p>
<h1 id="写在最后">写在最后</h1>
<p>MongoDB 是一个围绕开源技术产品成功创办一家公司的完美案例，也是在产品生命周期中如何选择正确时机转向的绝佳例子。MongoDB 的简单性和较小的安装体积可以在不增加很多开销的情况下构建复杂的系统。我希望 MongoDB 公司在未来几年继续为社区版提供支持。</p>
<p><strong>原文链接</strong><br>
<a href="https://www.quickprogrammingtips.com/mongodb/mongodb-history.html">MongoDB History</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[云计算与人工智能]]></title>
        <id>https://yeolar.github.io/post/yun-ji-suan-yu-ren-gong-zhi-neng/</id>
        <link href="https://yeolar.github.io/post/yun-ji-suan-yu-ren-gong-zhi-neng/">
        </link>
        <updated>2020-10-30T13:54:09.000Z</updated>
        <summary type="html"><![CDATA[<p>我今天要讲这三个话题，一个是云计算，一个大数据，一个人工智能，我为什么要讲这三个东西呢？因为这三个东西现在非常非常的火，它们之间好像互相有关系，一般谈云计算的时候也会提到大数据，谈人工智能的时候也会提大数据，谈人工智能的时候也会提云计算。所以说感觉他们又相辅相成不可分割，如果是非技术的人员来讲可能比较难理解说这三个之间的相互关系，所以有必要解释一下。</p>
]]></summary>
        <content type="html"><![CDATA[<p>我今天要讲这三个话题，一个是云计算，一个大数据，一个人工智能，我为什么要讲这三个东西呢？因为这三个东西现在非常非常的火，它们之间好像互相有关系，一般谈云计算的时候也会提到大数据，谈人工智能的时候也会提大数据，谈人工智能的时候也会提云计算。所以说感觉他们又相辅相成不可分割，如果是非技术的人员来讲可能比较难理解说这三个之间的相互关系，所以有必要解释一下。</p>
<!-- more -->
<h1 id="一-云计算最初是实现资源管理的灵活性">一、云计算最初是实现资源管理的灵活性</h1>
<p>我们首先来说云计算，云计算最初的目标是对资源的管理，管理的主要是计算资源，网络资源，存储资源三个方面。</p>
<figure data-type="image" tabindex="1"><img src="https://yeolar.github.io/post-images/1604066295169.jpeg" alt="" loading="lazy"></figure>
<h2 id="11-管数据中心就像配电脑">1.1 管数据中心就像配电脑</h2>
<p>什么叫计算，网络，存储资源呢？就说你要买台笔记本电脑吧，你是不是要关心这台电脑什么样的CPU啊？多大的内存啊？这两个我们称为计算资源。</p>
<p>这台电脑要能上网吧，需要有个网口可以插网线，或者有无线网卡可以连接我们家的路由器，您家也需要到运营商比如联通，移动，电信开通一个网络，比如100M的带宽，然后会有师傅弄一根网线到您家来，师傅可能会帮您将您的路由器和他们公司的网络连接配置好，这样您家的所有的电脑，手机，平板就都可以通过您的路由器上网了。这就是网络。</p>
<p>您可能还会问硬盘多大啊？原来硬盘都很小，10G之类的，后来500G，1T，2T的硬盘也不新鲜了。(1T是1000G)，这就是存储。</p>
<p>对于一台电脑是这个样子的，对于一个数据中心也是同样的。想象你有一个非常非常大的机房，里面堆了很多的服务器，这些服务器也是有CPU，内存，硬盘的，也是通过类似路由器的设备上网的。这个时候的一个问题就是，运营数据中心的人是怎么把这些设备统一的管理起来的呢？</p>
<h2 id="12-灵活就是想啥时要都有想要多少都行">1.2 灵活就是想啥时要都有，想要多少都行</h2>
<p>管理的目标就是要达到两个方面的灵活性。哪两个方面呢？比如有个人需要一台很小很小的电脑，只有一个CPU，1G内存，10G的硬盘，一兆的带宽，你能给他吗？像这种这么小规格的电脑，现在随便一个笔记本电脑都比这个配置强了，家里随便拉一个宽带都要100M。然而如果去一个云计算的平台上，他要想要这个资源的时候，只要一点就有了。</p>
<p>所以说它就能达到两个方面灵活性。</p>
<ul>
<li>第一个方面就是想什么时候要就什么时候要，比如需要的时候一点就出来了，这个叫做时间灵活性。</li>
<li>第二个方面就是想要多少呢就有多少，比如需要一个很小很小的电脑，可以满足，比如需要一个特别大的空间，以云盘为例，似乎云盘给每个人分配的空间动不动就就很大很大，随时上传随时有空间，永远用不完，这个叫做空间灵活性。</li>
</ul>
<p>空间灵活性和时间灵活性，也即我们常说的云计算的弹性。</p>
<p>为了解决这个弹性的问题，经历了漫长时间的发展。</p>
<h2 id="13-物理设备不灵活">1.3 物理设备不灵活</h2>
<p>首先第一个阶段就是物理机，或者说物理设备时期。这个时期相当于客户需要一台电脑，我们就买一台放在数据中心里。物理设备当然是越来越牛，例如服务器，内存动不动就是百G内存，例如网络设备，一个端口的带宽就能有几十G甚至上百G，例如存储，在数据中心至少是PB级别的(一个P是1000个T，一个T是1000个G)。</p>
<p>然而物理设备不能做到很好的灵活性。首先它不能够达到想什么时候要就什么时候要、比如买台服务器，哪怕买个电脑，都有采购的时间。突然用户告诉某个云厂商，说想要开台电脑，如果使用物理服务器，当时去采购啊就很难，如果说供应商啊关系一般，可能采购一个月，供应商关系好的话也需要一个星期。用户等了一个星期后，这时候电脑才到位，用户还要登录上去开始慢慢部署自己的应用，时间灵活性非常差。第二是空间灵活性也不行，例如上述的用户，要一个很小很小的电脑，现在哪还有这么小型号的电脑啊。不能为了满足用户只要一个G的内存是80G硬盘的，就去买一个这么小的机器。但是如果买一个大的呢，因为电脑大，就向用户多收钱，用户说他只用这么小的一点，如果让用户多付钱就很冤。</p>
<h2 id="14-虚拟化灵活多了">1.4 虚拟化灵活多了</h2>
<p>有人就想办法了。第一个办法就是虚拟化。用户不是只要一个很小的电脑么？数据中心的物理设备都很强大，我可以从物理的CPU，内存，硬盘中虚拟出一小块来给客户，同时也可以虚拟出一小块来给其他客户，每个客户都只能看到自己虚的那一小块，其实每个客户用的是整个大的设备上其中的一小块。虚拟化的技术能使得不同的客户的电脑看起来是隔离的，我看着好像这块盘就是我的，你看这呢这块盘就是你的，实际情况可能我这个10G和您这个10G是落在同样一个很大很大的这个存储上的。</p>
<p>而且如果事先物理设备都准备好，虚拟化软件虚拟出一个电脑是非常快的，基本上几分钟就能解决。所以在任何一个云上要创建一台电脑，一点几分钟就出来了，就是这个道理。</p>
<p>这个空间灵活性和时间灵活性就基本解决了。</p>
<h2 id="15-虚拟世界的赚钱与情怀">1.5 虚拟世界的赚钱与情怀</h2>
<p>在虚拟化阶段，最牛的公司是Vmware，是实现虚拟化技术比较早的一家公司，可以实现计算，网络，存储的虚拟化，这家公司很牛，性能也做得非常好，然后虚拟化软件卖的也非常好，赚了好多的钱，后来让EMC(世界五百强，存储厂商第一品牌)给收购了。</p>
<p>但是这个世界上还是有很多有情怀的人的，尤其是程序员里面，有情怀的人喜欢做一件什么事情呢？开源。这个世界上很多软件都是有闭源就有开源，源就是源代码。就是说某个软件做的好，所有人都爱用，这个软件的代码呢，我封闭起来只有我公司知道，其他人不知道，如果其他人想用这个软件，就要付我钱，这就叫闭源。但是世界上总有一些大牛看不惯钱都让一家赚了去。大牛们觉得，这个技术你会我也会，你能开发出来，我也能，我开发出来就是不收钱，把代码拿出来分享给大家，全世界谁用都可以，所有的人都可以享受到好处，这个叫做开源。</p>
<p>比如最近蒂姆·伯纳斯·李就是个非常有情怀的人，2017年，他因“发明万维网、第一个浏览器和使万维网得以扩展的基本协议和算法”而获得2016年度的图灵奖。图灵奖就是计算机界的诺贝尔奖。然而他最令人敬佩的是，他将万维网，也就是我们常见的www的技术无偿贡献给全世界免费使用。我们现在在网上的所有行为都应该感谢他的功劳，如果他将这个技术拿来收钱，应该和比尔盖茨差不多有钱。</p>
<p>例如在闭源的世界里有windows，大家用windows都得给微软付钱，开源的世界里面就出现了Linux。比尔盖茨靠windows，Office这些闭源的软件赚了很多钱，称为世界首富，就有大牛开发了另外一种操作系统Linux。很多人可能没有听说过Linux，很多后台的服务器上跑的程序都是Linux上的，比如大家享受双十一，支撑双十一抢购的系统，无论是淘宝，京东，考拉，都是跑在Linux上的。</p>
<p>再如有apple就有安卓。apple市值很高，但是苹果系统的代码我们是看不到的。于是就有大牛写了安卓手机操作系统。所以大家可以看到几乎所有的其他手机厂商，里面都装安卓系统，因为苹果系统不开源，而安卓系统大家都可以用。</p>
<p>在虚拟化软件也一样，有了Vmware，这个软件非常非常的贵。那就有大牛写了两个开源的虚拟化软件，一个叫做Xen，一个叫做KVM，如果不做技术的，可以不用管这两个名字，但是后面还是会提到。</p>
<h2 id="16-虚拟化的半自动和云计算的全自动">1.6 虚拟化的半自动和云计算的全自动</h2>
<p>虚拟化软件似乎解决了灵活性问题，其实不全对。因为虚拟化软件一般创建一台虚拟的电脑，是需要人工指定这台虚拟电脑放在哪台物理机上的，可能还需要比较复杂的人工配置，所以使用Vmware的虚拟化软件，需要考一个很牛的证书，能拿到这个证书的人，薪资是相当的高，也可见复杂程度。所以仅仅凭虚拟化软件所能管理的物理机的集群规模都不是特别的大，一般在十几台，几十台，最多百台这么一个规模。这一方面会影响时间灵活性，虽然虚拟出一台电脑的时间很短，但是随着集群规模的扩大，人工配置的过程越来越复杂，越来越耗时。另一方面也影响空间灵活性，当用户数量多的时候，这点集群规模，还远达不到想要多少要多少的程度，很可能这点资源很快就用完了，还得去采购。所以随着集群的规模越来越大，基本都是千台起步，动辄上万台，甚至几十上百万台，如果去查一下BAT，包括网易，包括谷歌，亚马逊，服务器数目都大的吓人。这么多机器要靠人去选一个位置放这台虚拟化的电脑并做相应的配置，几乎是不可能的事情，还是需要机器去做这个事情。</p>
<p>人们发明了各种各样的算法来做这个事情，算法的名字叫做调度(Scheduler)。通俗一点的说，就是有一个调度中心，几千台机器都在一个池子里面，无论用户需要多少CPU，内存，硬盘的虚拟电脑，调度中心会自动在大池子里面找一个能够满足用户需求的地方，把虚拟电脑启动起来做好配置，用户就直接能用了。这个阶段，我们称为池化，或者云化，到了这个阶段，才可以称为云计算，在这之前都只能叫虚拟化。</p>
<h2 id="17-云计算的私有与公有">1.7 云计算的私有与公有</h2>
<p>云计算大致分两种，一个是私有云，一个是公有云，还有人把私有云和公有云连接起来称为混合云，我们暂且不说这个。私有云就是把虚拟化和云化的这套软件部署在别人的数据中心里面，使用私有云的用户往往很有钱，自己买地建机房，自己买服务器，然后让云厂商部署在自己这里，Vmware后来除了虚拟化，也推出了云计算的产品，并且在私有云市场赚的盆满钵满。所谓公有云就是虚拟化和云化软件部署在云厂商自己数据中心里面的，用户不需要很大的投入，只要注册一个账号，就能在一个网页上点一下创建一台虚拟电脑，例如AWS也即亚马逊的公有云，例如国内的阿里云，腾讯云，网易云等。</p>
<p>亚马逊呢为什么要做公有云呢？我们知道亚马逊原来是国外比较大的一个电商，它做电商的时候也肯定会遇到类似双11的场景，在某一个时刻大家都冲上来买东西。当大家都冲上买东西的时候，就特别需要云的时间灵活性和空间灵活性。因为它不能时刻准备好所有的资源，那样太浪费了。但也不能什么都不准备，看着双十一这么多用户想买东西登不上去。所以需要双十一的时候，创建一大批虚拟电脑来支撑电商应用，过了双十一再把这些资源都释放掉去干别的。所以亚马逊是需要一个云平台的。</p>
<p>然而商用的虚拟化软件实在是太贵了，亚马逊总不能把自己在电商赚的钱全部给了虚拟化厂商吧。于是亚马逊基于开源的虚拟化技术，如上所述的Xen或者KVM，开发了一套自己的云化软件。没想到亚马逊后来电商越做越牛，云平台也越做越牛。而且由于他的云平台需要支撑自己的电商应用，而传统的云计算厂商多为IT厂商出身，几乎没有自己的应用，因而亚马逊的云平台对应用更加的友好，迅速发展成为云计算的第一品牌，赚了很多钱。在亚马逊公布其云计算平台财报之前，人们都猜测，亚马逊电商赚钱，云也赚钱吗？后来一公布财报，发现不是一般的赚钱，仅仅去年，亚马逊AWS年营收达122亿美元，运营利润31亿美元。</p>
<h2 id="18-云计算的赚钱与情怀">1.8 云计算的赚钱与情怀</h2>
<p>公有云的第一名亚马逊过得很爽，第二名Rackspace过的就一般了。没办法，这就是互联网行业的残酷性，多是赢者通吃的模式。所以第二名如果不是云计算行业的，很多人可能都没听过了。第二名就想，我干不过老大怎么办呢？开源吧。如上所述，亚马逊虽然使用了开源的虚拟化技术，但是云化的代码是闭源的，很多想做又做不了云化平台的公司，只能眼巴巴的看着亚马逊挣大钱。Rackspace把源代码一公开，整个行业就可以一起把这个平台越做越好，兄弟们大家一起上，和老大拼了。</p>
<p>于是Rackspace和美国航空航天局合作创办了开源软件OpenStack，如图所示OpenStack的架构图，不是云计算行业的不用弄懂这个图，但是能够看到三个关键字，Compute计算，Networking网络，Storage存储。还是一个计算，网络，存储的云化管理平台。</p>
<p>当然第二名的技术也是非常棒的，有了OpenStack之后，果真像Rackspace想象的一样，所有想做云的大企业都疯了，你能想象到的所有如雷贯耳的大型IT企业，IBM，惠普，戴尔，华为，联想等等，都疯了。原来云平台大家都想做，看着亚马逊和Vmware赚了这么多钱，眼巴巴看着没办法，想自己做一个好像难度还挺大。现在好了，有了这样一个开源的云平台OpenStack，所有的IT厂商都加入到这个社区中来，对这个云平台进行贡献，包装成自己的产品，连同自己的硬件设备一起卖。有的做了私有云，有的做了公有云，OpenStack已经成为开源云平台的事实标准。</p>
<h2 id="19-iaas-资源层面的灵活性">1.9 IaaS, 资源层面的灵活性</h2>
<p>随着OpenStack的技术越来越成熟，可以管理的规模也越来越大，并且可以有多个OpenStack集群部署多套，比如北京部署一套，杭州部署两套，广州部署一套，然后进行统一的管理。这样整个规模就更大了。在这个规模下，对于普通用户的感知来讲，基本能够做到想什么时候要就什么时候要，想要多少就要多少。还是拿云盘举例子，每个用户云盘都分配了5T甚至更大的空间，如果有1亿人，那加起来空间多大啊。其实背后的机制是这样的，分配你的空间，你可能只用了其中很少一点，比如说它分配给你了5个T，这么大的空间仅仅是你看到的，而不是真的就给你了，你其实只用了50个G，则真实给你的就是50个G，随着你文件的不断上传，分给你的空间会越来越多。当大家都上传，云平台发现快满了的时候(例如用了70%)，会采购更多的服务器，扩充背后的资源，这个对用户是透明的，看不到的，从感觉上来讲，就实现了云计算的弹性。其实有点像银行，给储户的感觉是什么时候取钱都有，只要不同时挤兑，银行就不会垮。</p>
<p>这里做一个简单的总结，到了这个阶段，云计算基本上实现了时间灵活性和空间灵活性，实现了计算，网络，存储资源的弹性。计算，网络，存储我们常称为基础设施Infranstracture, 因而这个阶段的弹性称为资源层面的弹性，管理资源的云平台，我们称为基础设施服务，就是我们常听到的IaaS，Infranstracture As A Service。</p>
<h1 id="二-云计算不光管资源也要管应用">二、云计算不光管资源，也要管应用</h1>
<figure data-type="image" tabindex="2"><img src="https://yeolar.github.io/post-images/1604136183344.jpeg" alt="" loading="lazy"></figure>
<p>有了IaaS，实现了资源层面的弹性就够了吗？显然不是。还有应用层面的弹性。这里举个例子，比如说实现一个电商的应用，平时十台机器就够了，双十一需要一百台。你可能觉得很好办啊，有了IaaS，新创建九十台机器就可以了啊。但是90台机器创建出来是空的啊，电商应用并没有放上去啊，只能你公司的运维人员一台一台的弄，还是需要很长时间才能安装好的。虽然资源层面实现了弹性，但是没有应用层的弹性，依然灵活性是不够的。</p>
<p>有没有方法解决这个问题呢？于是人们在IaaS平台之上又加了一层，用于管理资源以上的应用弹性的问题，这一层通常称为PaaS（Platform As A Service）。这一层往往比较难理解，其实大致分两部分，一部分我称为你自己的应用自动安装，一部分我称为通用的应用不用安装。</p>
<p>我们先来说第一部分，自己的应用自动安装。比如电商应用是你自己开发的，除了你自己，其他人是不知道怎么安装的，比如电商应用，安装的时候需要配置支付宝或者微信的账号，才能别人在你的电商上买东西的时候，付的钱是打到你的账户里面的，除了你，谁也不知道，所以安装的过程平台帮不了忙，但是能够帮你做的自动化，你需要做一些工作，将自己的配置信息融入到自动化的安装过程中方可。比如上面的例子，双十一新创建出来的90台机器是空的，如果能够提供一个工具，能够自动在这新的90台机器上将电商应用安装好，就能够实现应用层面的真正弹性。例如Puppet, Chef, Ansible, Cloud Foundary都可以干这件事情，最新的容器技术Docker能更好的干这件事情，不做技术的可以不用管这些词。</p>
<p>第二部分，通用的应用不用安装。所谓通用的应用，一般指一些复杂性比较高，但是大家都在用的，例如数据库。几乎所有的应用都会用数据库，但是数据库软件是标准的，虽然安装和维护比较复杂，但是无论谁安装都是一样。这样的应用可以变成标准的PaaS层的应用放在云平台的界面上。当用户需要一个数据库的时候，一点就出来了，用户就可以直接用了。有人问，既然谁安装都一个样，那我自己来好了，不需要花钱在云平台上买。当然不是，数据库是一个非常难的东西，光Oracle这家公司，靠数据库就能赚这么多钱。买Oracle也是要花很多很多钱的。然而大多数云平台会提供Mysql这样的开源数据库，又是开源，钱不需要花这么多了，但是维护这个数据库，却需要专门招一个很大的团队，如果这个数据库能够优化到能够支撑双十一，也不是一年两年能够搞定的。比如您是一个做单车的，当然没必要招一个非常大的数据库团队来干这件事情，成本太高了，应该交给云平台来做这件事情，专业的事情专业的人来做，云平台专门养了几百人维护这套系统，您只要专注于您的单车应用就可以了。</p>
<p>要么是自动部署，要么是不用部署，总的来说就是应用层你也要少操心，这就是PaaS层的重要作用。</p>
<figure data-type="image" tabindex="3"><img src="https://yeolar.github.io/post-images/1604138955538.jpeg" alt="" loading="lazy"></figure>
<p>虽说脚本的方式能够解决自己的应用的部署问题，然而不同的环境千差万别，一个脚本往往在一个环境上运行正确，到另一个环境就不正确了。</p>
<p>而容器是能更好的解决这个问题的。</p>
<figure data-type="image" tabindex="4"><img src="https://yeolar.github.io/post-images/1604139808999.jpeg" alt="" loading="lazy"></figure>
<p>容器是 Container，Container另一个意思是集装箱，其实容器的思想就是要变成软件交付的集装箱。集装箱的特点，一是封装，二是标准。</p>
<figure data-type="image" tabindex="5"><img src="https://yeolar.github.io/post-images/1604139947559.png" alt="" loading="lazy"></figure>
<p>在没有集装箱的时代，假设将货物从 A运到 B，中间要经过三个码头、换三次船。每次都要将货物卸下船来，摆的七零八落，然后搬上船重新整齐摆好。因此在没有集装箱的时候，每次换船，船员们都要在岸上待几天才能走。</p>
<figure data-type="image" tabindex="6"><img src="https://yeolar.github.io/post-images/1604139966106.png" alt="" loading="lazy"></figure>
<p>有了集装箱以后，所有的货物都打包在一起了，并且集装箱的尺寸全部一致，所以每次换船的时候，一个箱子整体搬过去就行了，小时级别就能完成，船员再也不用上岸长时间耽搁了。</p>
<p>这是集装箱“封装”、“标准”两大特点在生活中的应用。</p>
<figure data-type="image" tabindex="7"><img src="https://yeolar.github.io/post-images/1604140007933.png" alt="" loading="lazy"></figure>
<p>那么容器如何对应用打包呢？还是要学习集装箱，首先要有个封闭的环境，将货物封装起来，让货物之间互不干扰，互相隔离，这样装货卸货才方便。好在 Ubuntu中的LXC技术早就能做到这一点。</p>
<p>封闭的环境主要使用了两种技术，一种是看起来是隔离的技术，称为 Namespace，也即每个 Namespace中的应用看到的是不同的 IP地址、用户空间、程号等。另一种是用起来是隔离的技术，称为 Cgroups，也即明明整台机器有很多的 CPU、内存，而一个应用只能用其中的一部分。</p>
<p>所谓的镜像，就是将你焊好集装箱的那一刻，将集装箱的状态保存下来，就像孙悟空说：“定”，集装箱里面就定在了那一刻，然后将这一刻的状态保存成一系列文件。这些文件的格式是标准的，谁看到这些文件都能还原当时定住的那个时刻。将镜像还原成运行时的过程（就是读取镜像文件，还原那个时刻的过程）就是容器运行的过程。</p>
<p>有了容器，使得 PaaS层对于用户自身应用的自动部署变得快速而优雅。</p>
<h1 id="三-大数据拥抱云计算">三、大数据拥抱云计算</h1>
<p>在PaaS层中一个复杂的通用应用就是大数据平台。大数据是如何一步一步融入云计算的呢？</p>
<h2 id="31-数据不大也包含智慧">3.1 数据不大也包含智慧</h2>
<p>一开始这个大数据并不大，你想象原来才有多少数据？现在大家都去看电子书，上网看新闻了，在我们80后小时候，信息量没有那么大，也就看看书，看看报，一个星期的报纸加起来才有多少字啊，如果你不在一个大城市，一个普通的学校的图书馆加起来也没几个书架，是后来随着信息化的到来，信息才会越来越多。</p>
<p>首先我们来看一下大数据里面的数据，就分三种类型，一种叫结构化的数据，一种叫非结构化的数据，还有一种叫半结构化的数据。什么叫结构化的数据呢？叫有固定格式和有限长度的数据。例如填的表格就是结构化的数据，国籍：中华人民共和国，民族：汉，性别：男，这都叫结构化数据。现在越来越多的就是非结构化的数据，就是不定长，无固定格式的数据，例如网页，有时候非常长，有时候几句话就没了，例如语音，视频都是非结构化的数据。半结构化数据是一些xml或者html的格式的，不从事技术的可能不了解，但也没有关系。</p>
<p>数据怎么样才能对人有用呢？其实数据本身不是有用的，必须要经过一定的处理。例如你每天跑步带个手环收集的也是数据，网上这么多网页也是数据，我们称为Data，数据本身没有什么用处，但是数据里面包含一个很重要的东西，叫做信息Information，数据十分杂乱，经过梳理和清洗，才能够称为信息。信息会包含很多规律，我们需要从信息中将规律总结出来，称为知识knowledge，知识改变命运。信息是很多的，但是有人看到了信息相当于白看，但是有人就从信息中看到了电商的未来，有人看到了直播的未来，所以人家就牛了，你如果没有从信息中提取出知识，天天看朋友圈，也只能在互联网滚滚大潮中做个看客。有了知识，然后利用这些知识去应用于实战，有的人会做得非常好，这个东西叫做智慧intelligence。有知识并不一定有智慧，例如好多学者很有知识，已经发生的事情可以从各个角度分析的头头是道，但一到实干就歇菜，并不能转化成为智慧。而很多的创业家之所以伟大，就是通过获得的知识应用于实践，最后做了很大的生意。</p>
<p>所以数据的应用分这四个步骤：数据，信息，知识，智慧。这是很多商家都想要的，你看我收集了这么多的数据，能不能基于这些数据来帮我做下一步的决策，改善我的产品，例如让用户看视频的时候旁边弹出广告，正好是他想买的东西，再如让用户听音乐的时候，另外推荐一些他非常想听的其他音乐。用户在我的应用或者网站上随便点点鼠标，输入文字对我来说都是数据，我就是要将其中某些东西提取出来，指导实践，形成智慧，让用户陷入到我的应用里面不可自拔，上了我的网就不想离开，手不停的点，不停的买，很多人说双十一我都想断网了，我老婆在上面不断的买买买，买了A又推荐B，老婆大人说，“哎呀，B也是我喜欢的啊，老公我要买”。你说这个程序怎么这么牛，这么有智慧，比我还了解我老婆，这件事情是怎么做到的呢？</p>
<figure data-type="image" tabindex="8"><img src="https://yeolar.github.io/post-images/1604140820467.jpeg" alt="" loading="lazy"></figure>
<h2 id="32-数据如何升华为智慧">3.2 数据如何升华为智慧</h2>
<p>数据的处理分几个步骤，完成了才最后会有智慧。</p>
<p>第一个步骤叫数据的收集。首先得有数据，数据的收集有两个方式，第一个方式是拿，专业点的说法叫抓取或者爬取，例如搜索引擎就是这么做的，它把网上的所有的信息都下载到它的数据中心，然后你一搜才能搜出来。比如你去搜索的时候，结果会是一个列表，这个列表为什么会在搜索引擎的公司里面呢，就是因为他把这个数据啊都拿下来了，但是你一点链接，点出来这个网站就不在搜索引擎它们公司了。比如说新浪有个新闻，你拿百度搜出来，你不点的时候，那一页在百度数据中心，一点出来的网页就是在新浪的数据中心了。另外一个方式就是推送，有很多终端可以帮我收集数据，比如说小米手环，可以将你每天跑步的数据，心跳的数据，睡眠的数据都上传到数据中心里面。</p>
<p>第二个步骤是数据的传输。一般会通过队列方式进行，因为数据量实在是太大了，数据必须经过处理才会有用，可是系统处理不过来，只好排好队，慢慢的处理。</p>
<p>第三个步骤是数据的存储。现在数据就是金钱，掌握了数据就相当于掌握了钱。要不然网站怎么知道你想买什么呢？就是因为它有你历史的交易的数据，这个信息可不能给别人，十分宝贵，所以需要存储下来。</p>
<p>第四个步骤是数据的处理和分析。上面存储的数据是原始数据，原始数据多是杂乱无章的，有很多垃圾数据在里面，因而需要清洗和过滤，得到一些高质量的数据。对于高质量的数据，就可以进行分析，从而对数据进行分类，或者发现数据之间的相互关系，得到知识。比如盛传的沃尔玛超市的啤酒和尿布的故事，就是通过对人们的购买数据进行分析，发现了男人一般买尿布的时候，会同时购买啤酒，这样就发现了啤酒和尿布之间的相互关系，获得知识，然后应用到实践中，将啤酒和尿布的柜台弄的很近，就获得了智慧。</p>
<p>第五个步骤就是对于数据的检索和挖掘。检索就是搜索，所谓外事不决问google，内事不决问百度。内外两大搜索引擎都是讲分析后的数据放入搜索引擎，从而人们想寻找信息的时候，一搜就有了。另外就是挖掘，仅仅搜索出来已经不能满足人们的要求了，还需要从信息中挖掘出相互的关系。比如财经搜索，当搜索某个公司股票的时候，该公司的高管是不是也应该被挖掘出来呢？如果仅仅搜索出这个公司的股票发现涨的特别好，于是你就去买了，其实其高管发了一个声明，对股票十分不利，第二天就跌了，这不坑害广大股民么？所以通过各种算法挖掘数据中的关系，形成知识库，十分重要。</p>
<p><img src="https://yeolar.github.io/post-images/1604141242382.jpeg" alt="" loading="lazy"><br>
<img src="https://yeolar.github.io/post-images/1604141262561.jpeg" alt="" loading="lazy"></p>
<h2 id="33-大数据时代众人拾柴火焰高">3.3 大数据时代，众人拾柴火焰高</h2>
<p>当数据量很小的时候，很少的几台机器就能解决。慢慢的当数据量越来越大，最牛的服务器都解决不了问题的时候，就想怎么办呢？要聚合多台机器的力量，大家齐心协力一起把这个事搞定，众人拾柴火焰高。</p>
<p>对于数据的收集，对于IoT来讲，外面部署这成千上万的检测设备，将大量的温度，适度，监控，电力等等数据统统收集上来，对于互联网网页的搜索引擎来讲，需要将整个互联网所有的网页都下载下来，这显然一台机器做不到，需要多台机器组成网络爬虫系统，每台机器下载一部分，同时工作，才能在有限的时间内，将海量的网页下载完毕。</p>
<figure data-type="image" tabindex="9"><img src="https://yeolar.github.io/post-images/1604141536684.jpeg" alt="" loading="lazy"></figure>
<p>对于数据的传输，一个内存里面的队列肯定会被大量的数据挤爆掉，于是就产生了基于硬盘的分布式队列，这样队列可以多台机器同时传输，随你数据量多大，只要我的队列足够多，管道足够粗，就能够撑得住。</p>
<figure data-type="image" tabindex="10"><img src="https://yeolar.github.io/post-images/1604141721080.jpeg" alt="" loading="lazy"></figure>
<p>对于数据的存储，一台机器的文件系统肯定是放不下了，所以需要一个很大的分布式文件系统来做这件事情，把多台机器的硬盘打成一块大的文件系统。</p>
<figure data-type="image" tabindex="11"><img src="https://yeolar.github.io/post-images/1604141762190.jpeg" alt="" loading="lazy"></figure>
<p>再如数据的分析，可能需要对大量的数据做分解，统计，汇总，一台机器肯定搞不定，处理到猴年马月也分析不完，于是就有分布式计算的方法，将大量的数据分成小份，每台机器处理一小份，多台机器并行处理，很快就能算完。例如著名的Terasort对1个TB的数据排序，相当于1000G，如果单机处理，怎么也要几个小时，但是并行处理209秒就完成了。</p>
<p><img src="https://yeolar.github.io/post-images/1604141896534.jpeg" alt="" loading="lazy"><br>
<img src="https://yeolar.github.io/post-images/1604141923480.jpeg" alt="" loading="lazy"><br>
<img src="https://yeolar.github.io/post-images/1604141940076.jpeg" alt="" loading="lazy"></p>
<p>所以说大数据平台，什么叫做大数据，说白了就是一台机器干不完，大家一起干。随着数据量越来越大，很多不大的公司都需要处理相当多的数据，这些小公司没有这么多机器可怎么办呢？</p>
<h2 id="34-大数据需要云计算云计算需要大数据">3.4 大数据需要云计算，云计算需要大数据</h2>
<p>说到这里，大家想起云计算了吧。当想要干这些活的时候，需要好多好多的机器一块做，真的是想什么时候要，想要多少就要多少。例如大数据分析公司的财务情况，可能一周分析一次，如果要把这一百台机器或者一千台机器都在那放着，一周用一次对吧，非常浪费。那能不能需要计算的时候，把这一千台机器拿出来，然后不算的时候，这一千台机器可以去干别的事情。谁能做这个事儿呢？只有云计算，可以为大数据的运算提供资源层的灵活性。而云计算也会部署大数据放到它的PaaS平台上，作为一个非常非常重要的通用应用。因为大数据平台能够使得多台机器一起干一个事儿，这个东西不是一般人能开发出来的，也不是一般人玩得转的，怎么也得雇个几十上百号人才能把这个玩起来，所以说就像数据库一样，其实还是需要有一帮专业的人来玩这个东西。现在公有云上基本上都会有大数据的解决方案了，一个小公司我需要大数据平台的时候，不需要采购一千台机器，只要到公有云上一点，这一千台机器都出来了，并且上面已经部署好了的大数据平台，只要把数据放进去算就可以了。</p>
<p>云计算需要大数据，大数据需要云计算，两个人就这样结合了。</p>
<h1 id="四-人工智能拥抱大数据">四、人工智能拥抱大数据</h1>
<h2 id="41-机器什么时候才能懂人心">4.1 机器什么时候才能懂人心</h2>
<p>虽说有了大数据，人的欲望总是这个不能够满足。虽说在大数据平台里面有搜索引擎这个东西，想要什么东西我一搜就出来了。但是也存在这样的情况，我想要的东西不会搜，表达不出来，搜索出来的又不是我想要的。例如音乐软件里面推荐一首歌，这首歌我没听过，当然不知道名字，也没法搜，但是软件推荐给我，我的确喜欢，这就是搜索做不到的事情。当人们使用这种应用的时候，会发现机器知道我想要什么，而不是说当我想要的时候，去机器里面搜索。这个机器真像我的朋友一样懂我，这就有点人工智能的意思了。</p>
<p>人们很早就在想这个事情了。最早的时候，人们想象，如果要是有一堵墙，墙后面是个机器，我给它说话，它就给我回应，我如果感觉不出它那边是人还是机器，那它就真的是一个人工智能的东西了。</p>
<h2 id="42-让机器学会推理">4.2 让机器学会推理</h2>
<p>怎么才能做到这一点呢？人们就想：我首先要告诉计算机人类的推理的能力。你看人重要的是什么呀，人和动物的区别在什么呀，就是能推理。我要是把我这个推理的能力啊告诉机器，机器就能根据你的提问，推理出相应的回答，真能这样多好。推理其实人们慢慢的让机器能够做到一些了，例如证明数学公式。这是一个非常让人惊喜的一个过程，机器竟然能够证明数学公式。但是慢慢发现其实这个结果，也没有那么令人惊喜，因为大家发现了一个问题，数学公式非常严谨，推理过程也非常严谨，而且数学公式很容易拿机器来进行表达，程序也相对容易表达。然而人类的语言就没这么简单了，比如今天晚上，你和你女朋友约会，你女朋友说：如果你早来，我没来，你等着，如果我早来，你没来，你等着。这个机器就比比较难理解了，但是人都懂，所以你和女朋友约会，你是不敢迟到的。</p>
<h2 id="43-教给机器知识">4.3 教给机器知识</h2>
<p>所以仅仅告诉机器严格的推理是不够的，还要告诉机器一些知识。但是知识这个事儿，一般人可能就做不来了，可能专家可以，比如语言领域的专家，或者财经领域的专家。语言领域和财经领域知识能不能表示成像数学公式一样稍微严格点呢？例如语言专家可能会总结出主谓宾定状补这些语法规则，主语后面一定是谓语，谓语后面一定是宾语，将这些总结出来，并严格表达出来不久行了吗？后来发现这个不行，太难总结了，语言表达千变万化。就拿主谓宾的例子，很多时候在口语里面就省略了谓语，别人问：你谁啊？我回答：我刘超。但是你不能规定在语音语义识别的时候，要求对着机器说标准的书面语，这样还是不够智能，就像罗永浩在一次演讲中说的那样，每次对着手机，用书面语说：请帮我呼叫某某某，这是一件很尴尬的事情。</p>
<p>人工智能这个阶段叫做专家系统。专家系统不易成功，一方面是知识比较难总结，另一方面总结出来的知识难以教给计算机。因为你自己还迷迷糊糊，似乎觉得有规律，就是说不出来，就怎么能够通过编程教给计算机呢？</p>
<h2 id="44-算了教不会你自己学吧">4.4 算了，教不会你自己学吧</h2>
<p>于是人们想到，看来机器是和人完全不一样的物种，干脆让机器自己学习好了。机器怎么学习呢？既然机器的统计能力这么强，基于统计学习，一定能从大量的数字中发现一定的规律。</p>
<p>其实在娱乐圈有很好的一个例子，可见一斑</p>
<p>有一位网友统计了知名歌手在大陆发行的 9 张专辑中 117 首歌曲的歌词，同一词语在一首歌出现只算一次，形容词、名词和动词的前十名如下表所示（词语后面的数字是出现的次数）：</p>
<table>
<thead>
<tr>
<th>a</th>
<th>形容词</th>
<th>b</th>
<th>名词</th>
<th>c</th>
<th>动词</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>孤独:34</td>
<td>0</td>
<td>生命:50</td>
<td>0</td>
<td>爱:54</td>
</tr>
<tr>
<td>1</td>
<td>自由:17</td>
<td>1</td>
<td>路:37</td>
<td>1</td>
<td>碎:37</td>
</tr>
<tr>
<td>2</td>
<td>迷惘:16</td>
<td>2</td>
<td>夜:29</td>
<td>2</td>
<td>哭:35</td>
</tr>
<tr>
<td>3</td>
<td>坚强:13</td>
<td>3</td>
<td>天空:24</td>
<td>3</td>
<td>死:27</td>
</tr>
<tr>
<td>4</td>
<td>绝望:8</td>
<td>4</td>
<td>孩子:23</td>
<td>4</td>
<td>飞:26</td>
</tr>
<tr>
<td>5</td>
<td>青春:7</td>
<td>5</td>
<td>雨:21</td>
<td>5</td>
<td>梦想:14</td>
</tr>
<tr>
<td>6</td>
<td>迷茫:6</td>
<td>6</td>
<td>石头:9</td>
<td>6</td>
<td>祈祷:10</td>
</tr>
<tr>
<td>7</td>
<td>光明:6</td>
<td>7</td>
<td>鸟:9</td>
<td>7</td>
<td>离去:10</td>
</tr>
</tbody>
</table>
<p>如果我们随便写一串数字，然后按照数位依次在形容词、名词和动词中取出一个词，连在一起会怎么样呢？</p>
<p>例如取圆周率 3.1415926，对应的词语是：坚强，路，飞，自由，雨，埋，迷惘。稍微连接和润色一下：</p>
<p>坚强的孩子，</p>
<p>依然前行在路上，</p>
<p>张开翅膀飞向自由，</p>
<p>让雨水埋葬他的迷惘。</p>
<p>是不是有点感觉了？当然真正基于统计的学习算法比这个简单的统计复杂的多。</p>
<p>然而统计学习比较容易理解简单的相关性，例如一个词和另一个词总是一起出现，两个词应该有关系，而无法表达复杂的相关性，并且统计方法的公式往往非常复杂，为了简化计算，常常做出各种独立性的假设，来降低公式的计算难度，然而现实生活中，具有独立性的事件是相对较少的。</p>
<h2 id="45-模拟大脑的工作方式">4.5 模拟大脑的工作方式</h2>
<p>于是人类开始从机器的世界，反思人类的世界是怎么工作的。</p>
<figure data-type="image" tabindex="12"><img src="https://yeolar.github.io/post-images/1604143292462.jpeg" alt="" loading="lazy"></figure>
<p>人类的脑子里面不是存储着大量的规则，也不是记录着大量的统计数据，而是通过神经元的触发实现的，每个神经元有从其他神经元的输入，当接收到输入的时候，会产生一个输出来刺激其他的神经元，于是大量的神经元相互反应，最终形成各种输出的结果。例如当人们看到美女瞳孔放大，绝不是大脑根据身材比例进行规则判断，也不是将人生中看过的所有的美女都统计一遍，而是神经元从视网膜触发到大脑再回到瞳孔。在这个过程中，其实很难总结出每个神经元对最终的结果起到了哪些作用，反正就是起作用了。</p>
<p>于是人们开始用一个数学单元模拟神经元</p>
<p>这个神经元有输入，有输出，输入和输出之间通过一个公式来表示，输入根据重要程度不同(权重)，影响着输出。</p>
<figure data-type="image" tabindex="13"><img src="https://yeolar.github.io/post-images/1604143395812.jpeg" alt="" loading="lazy"></figure>
<p>于是将n个神经元通过像一张神经网络一样连接在一起，n这个数字可以很大很大，所有的神经元可以分成很多列，每一列很多个排列起来，每个神经元的对于输入的权重可以都不相同，从而每个神经元的公式也不相同。当人们从这张网络中输入一个东西的时候，希望输出一个对人类来讲正确的结果。例如上面的例子，输入一个写着2的图片，输出的列表里面第二个数字最大，其实从机器来讲，它既不知道输入的这个图片写的是2，也不知道输出的这一系列数字的意义，没关系，人知道意义就可以了。正如对于神经元来说，他们既不知道视网膜看到的是美女，也不知道瞳孔放大是为了看的清楚，反正看到美女，瞳孔放大了，就可以了。</p>
<p>对于任何一张神经网络，谁也不敢保证输入是2，输出一定是第二个数字最大，要保证这个结果，需要训练和学习。毕竟看到美女而瞳孔放大也是人类很多年进化的结果。学习的过程就是，输入大量的图片，如果结果不是想要的结果，则进行调整。如何调整呢，就是每个神经元的每个权重都向目标进行微调，由于神经元和权重实在是太多了，所以整张网络产生的结果很难表现出非此即彼的结果，而是向着结果微微的进步，最终能够达到目标结果。当然这些调整的策略还是非常有技巧的，需要算法的高手来仔细的调整。正如人类见到美女，瞳孔一开始没有放大到能看清楚，于是美女跟别人跑了，下次学习的结果是瞳孔放大一点点，而不是放大鼻孔。</p>
<h2 id="46-没道理但做得到">4.6 没道理但做得到</h2>
<p>听起来也没有那么有道理，但是的确能做到，就是这么任性。</p>
<p>神经网络的普遍性定理是这样说的，假设某个人给你某种复杂奇特的函数，f(x)：</p>
<figure data-type="image" tabindex="14"><img src="https://yeolar.github.io/post-images/1604143551203.jpeg" alt="" loading="lazy"></figure>
<p>不管这个函数是什么样的，总会确保有个神经网络能够对任何可能的输入x，其值f(x)（或者某个能够准确的近似）是神经网络的输出。</p>
<p>如果在函数代表着规律，也意味着这个规律无论多么奇妙，多么不能理解，都是能通过大量的神经元，通过大量权重的调整，表示出来的。</p>
<h2 id="47-人工智能的经济学解释">4.7 人工智能的经济学解释</h2>
<p>这让我想到了经济学，于是比较容易理解了。</p>
<figure data-type="image" tabindex="15"><img src="https://yeolar.github.io/post-images/1604143646353.png" alt="" loading="lazy"></figure>
<p>我们把每个神经元当成社会中从事经济活动的个体。于是神经网络相当于整个经济社会，每个神经元对于社会的输入，都有权重的调整，做出相应的输出，比如工资涨了，菜价也涨了，股票跌了，我应该怎么办，怎么花自己的钱。这里面没有规律么？肯定有，但是具体什么规律呢？却很难说清楚。</p>
<p>基于专家系统的经济属于计划经济，整个经济规律的表示不希望通过每个经济个体的独立决策表现出来，而是希望通过专家的高屋建瓴和远见卓识总结出来。专家永远不可能知道哪个城市的哪个街道缺少一个卖甜豆腐脑的。于是专家说应该产多少钢铁，产多少馒头，往往距离人民生活的真正需求有较大的差距，就算整个计划书写个几百页，也无法表达隐藏在人民生活中的小规律。</p>
<p>基于统计的宏观调控就靠谱的多了，每年统计局都会统计整个社会的就业率，通胀率，GDP等等指标，这些指标往往代表着很多的内在规律，虽然不能够精确表达，但是相对靠谱。然而基于统计的规律总结表达相对比较粗糙，比如经济学家看到这些统计数据可以总结出长期来看房价是涨还是跌，股票长期来看是涨还是跌，如果经济总体上扬，房价和股票应该都是涨的。但是基于统计数据，无法总结出股票，物价的微小波动规律。</p>
<p>基于神经网络的微观经济学才是对整个经济规律最最准确的表达，每个人对于从社会中的输入，进行各自的调整，并且调整同样会作为输入反馈到社会中。想象一下股市行情细微的波动曲线，正是每个独立的个体各自不断交易的结果，没有统一的规律可循。而每个人根据整个社会的输入进行独立决策，当某些因素经过多次训练，也会形成宏观上的统计性的规律，这也就是宏观经济学所能看到的。例如每次货币大量发行，最后房价都会上涨，多次训练后，人们也就都学会了。</p>
<h2 id="48-人工智能需要大数据">4.8 人工智能需要大数据</h2>
<p>然而神经网络包含这么多的节点，每个节点包含非常多的参数，整个参数量实在是太大了，需要的计算量实在太大，但是没有关系啊，我们有大数据平台，可以汇聚多台机器的力量一起来计算，才能在有限的时间内得到想要的结果。</p>
<p>人工智能可以做的事情非常多，例如可以鉴别垃圾邮件，鉴别黄色暴力文字和图片等。这也是经历了三个阶段的。第一个阶段依赖于关键词黑白名单和过滤技术，包含哪些词就是黄色或者暴力的文字。随着这个网络语言越来越多，词也不断的变化，不断的更新这个词库就有点顾不过来。第二个阶段时，基于一些新的算法，比如说贝叶斯过滤等，你不用管贝叶斯算法是什么，但是这个名字你应该听过，这个一个基于概率的算法。第三个阶段就是基于大数据和人工智能，进行更加精准的用户画像和文本理解和图像理解。</p>
<p>由于人工智能算法多是依赖于大量的数据的，这些数据往往需要面向某个特定的领域(例如电商，邮箱)进行长期的积累，如果没有数据，就算有人工智能算法也白搭，所以人工智能程序很少像前面的IaaS和PaaS一样，将人工智能程序给某个客户安装一套让客户去用，因为给某个客户单独安装一套，客户没有相关的数据做训练，结果往往是很差的。但是云计算厂商往往是积累了大量数据的，于是就在云计算厂商里面安装一套，暴露一个服务接口，比如您想鉴别一个文本是不是涉及黄色和暴力，直接用这个在线服务就可以了。这种形势的服务，在云计算里面称为软件即服务，SaaS (Software AS A Service)</p>
<p>于是工智能程序作为SaaS平台进入了云计算。</p>
<h1 id="五-云计算大数据人工智能过上了美好的生活">五、云计算，大数据，人工智能过上了美好的生活</h1>
<p>终于云计算的三兄弟凑齐了，分别是IaaS，PaaS和SaaS，所以一般在一个云计算平台上，云，大数据，人工智能都能找得到。对一个大数据公司，积累了大量的数据，也会使用一些人工智能的算法提供一些服务。对于一个人工智能公司，也不可能没有大数据平台支撑。所以云计算，大数据，人工智能就这样整合起来，完成了相遇，相识，相知。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[云计算到底是谁发明的？]]></title>
        <id>https://yeolar.github.io/post/yun-ji-suan-dao-di-shi-shui-fa-ming-de/</id>
        <link href="https://yeolar.github.io/post/yun-ji-suan-dao-di-shi-shui-fa-ming-de/">
        </link>
        <updated>2020-10-30T13:29:57.000Z</updated>
        <content type="html"><![CDATA[<p>说到云计算的起源，公众普遍认为，谷歌前CEO埃里克·施密特是云计算概念的第一个提出者。</p>
<p>2006年8月9日，在搜索引擎大会（SES San Jose 2006）上，他提出了“云计算（Cloud Computing）”的概念。</p>
<p><img src="https://yeolar.github.io/post-images/1604064679197.png" alt="" loading="lazy"><br>
埃里克·施密特（Eric Schmidt）</p>
<p>也有人认为，当今云计算市场的龙头老大——美国亚马逊（Amazon）公司，在更早的2006年3月，就正式推出了自家的弹性计算云（Elastic Compute Cloud，EC2）服务，是事实上的云计算开创者。</p>
<figure data-type="image" tabindex="1"><img src="https://yeolar.github.io/post-images/1604064752951.png" alt="" loading="lazy"></figure>
<p>其实，准确来说，不管是谷歌还是亚马逊，都不是云计算的发明人。云计算概念的提出，远比我们想象中要早得多。</p>
<p>今天这篇文章，我们就针对云计算来一次彻底的“寻根问祖”。</p>
<figure data-type="image" tabindex="2"><img src="https://yeolar.github.io/post-images/1604064788996.png" alt="" loading="lazy"></figure>
<h1 id="part1-公共计算云计算理论的萌芽">Part.1  公共计算——云计算理论的萌芽</h1>
<p>大家应该还记得，我们的计算机通识课本里说过，世界上第一台电子计算机是ENIAC（埃尼阿克）。</p>
<p><img src="https://yeolar.github.io/post-images/1604064812675.jpeg" alt="" loading="lazy"><br>
Electronic Numerical Integrator And Computer</p>
<p>电子数字积分计算机</p>
<p>其实，严谨来说，ENIAC只能算是世界上第二台电子计算机。在它之前，还有一台名叫阿塔纳索夫-贝瑞（Atanasoff–Berry Computer）的计算机，简称ABC计算机。只不过这台ABC计算机不可编程，所以ENIAC是第一台通用电子计算机。</p>
<p>ENIAC的出现，宣告了计算时代的开始，从此人类打开了计算机世界的大门。</p>
<p>像ENIAC这样的早期计算机，体型巨大、耗资昂贵，计算能力也非常有限。最重要的是，它缺乏多用户能力，同一时间只能被一个人占用。大家都想用的话，只能排队。</p>
<p>1955年，美国麻省理工学院（MIT）的约翰·麦卡锡（John McCarthy）教授提出了time-sharing（分时）的技术理念，希望借此可以满足多人同时使用一台计算机的诉求。</p>
<p><img src="https://yeolar.github.io/post-images/1604064883430.jpeg" alt="" loading="lazy"><br>
约翰·麦卡锡（1927-2011）</p>
<p>这个约翰·麦卡锡大家应该很眼熟，没错，他就是Artificial Intelligence（AI）概念的提出者，世界公认的人工智能之父，后来在1971年获得了图灵奖。</p>
<p>无独有偶，1959年6月，英国计算机科学家克里斯托弗·斯特雷奇（Christopher Strachey）在国际信息处理大会上，发表了一篇学术论文，也是关于大型机共享使用的，名字叫做**《大型高速计算机中的时间共享（Time Sharing in Large Fast Computer）》**。</p>
<p><img src="https://yeolar.github.io/post-images/1604064913875.jpeg" alt="" loading="lazy"><br>
克里斯托弗·斯特雷奇（1916-1975）</p>
<p>在这篇论文中，<strong>虚拟化</strong>的概念被首次提出。现在我们都知道，虚拟化是如今云计算架构的基石。当时那篇论文，绝对堪称“惊为天人”。</p>
<p>到了1961年，又是咱们的大神约翰·麦卡锡，在麻省理工学院一百周年纪念庆典上，首次提出了**Utility Computing（公共计算服务）**的概念：</p>
<p>“如果我设想的那种计算机（注：即分时计算机，同时支持多人同时使用的计算机）能够成真，那么计算或许某天会像电话一样被组织成公共服务…… Utility Computing（公共计算服务）将是一种全新的重要工业的基础。”</p>
<p>这个Utility Computing的翻译，其实行业里存在一定的争议。Utility有“公共服务、实用、效用”的意思，有人把它翻译成公共计算，也有人翻译成效用计算。</p>
<p>麦卡锡的理念，其实借鉴了传统的电厂模式。</p>
<p>说白了，就是把计算资源当作是一种像电一样的能源资源。用户可以像把灯泡插入插座一样，随时随地使用计算资源，并根据使用量进行付费。</p>
<p>受麦卡锡观点的影响，麻省理工学院和DARPA（美国国防高级研究计划局）下属的IPTO（信息处理技术办公室）共同启动了著名的<strong>MAC（Multiple Access Computing）项目</strong>。DARPA还专门提供了约200万美元的项目津贴。</p>
<p>MAC项目的目标，就是开发“多人可同时使用的电脑系统”。实际上，这就是“云”和“虚拟化”技术的雏形。</p>
<p>1964年，大西洋月刊发表了一篇题为《The Computers of Tomorrow（明日计算机）》的文章，详细分析了公共计算服务与公共电网的异同点。</p>
<p>文章指出，计算想要成为像电网那样的公共服务，需要关注三个问题：</p>
<ul>
<li>接口——用户如何和资源进行对接？</li>
<li>服务设备——用户通过什么设备将资源转换成服务？</li>
<li>产品同质性——电总归是电，而计算是一种复杂的服务，存在多样性，存在不同的编程语言和硬件，如何兼容、交互？</li>
</ul>
<p>1965年，在《The Computers of Tomorrow》的影响下，MAC项目组开始开发<strong>Multics分时多任务操作系统</strong>。在这个过程中，GE（通用电气）被选为硬件供应商，IBM出局。贝尔实验室后来也加入到MAC的软件开发中。</p>
<p>1965年，从MAC中出局的IBM开始研发CP-40/CMS分时操作系统，该系统于1967年发布，是<strong>历史上第一个虚拟机系统</strong>。</p>
<p>1969年，受不了Multics缓慢进展的贝尔实验室从MAC项目退出，开始开发<strong>Unix操作系统（1970年问世）</strong>。</p>
<p>1969年，在约瑟夫·利克莱德（J.C.R.Licklider，IPTO负责人）的推动下，ARPA（国防部高级研究计划局）研究的计算机网络<strong>ARPANET</strong>诞生。</p>
<p>我相信大家都认识ARPANET，没错，这就是后来的Internet。</p>
<p><img src="https://yeolar.github.io/post-images/1604064983930.jpeg" alt="" loading="lazy"><br>
约瑟夫·利克莱德（1915-1990）</p>
<p>自此，云计算所依赖的三大底层技术全部出现了：</p>
<ul>
<li>用于管理物理计算资源的操作系统</li>
<li>用于把资源分给多人同时使用的虚拟化技术</li>
<li>用于远程接入的互联网</li>
</ul>
<h1 id="part2-网格计算云计算理念的复苏">Part.2  网格计算——云计算理念的复苏</h1>
<p>虽然云计算基础技术纷纷出现，但20世纪70-80年代，人们沉浸于PC市场的繁荣，主要精力都放在了软件和网络上，进而忽视了对Utility Computing的关注。</p>
<p>1984年，SUN公司联合创始人John Gage（约翰·盖奇）提出** “网络就是计算机（The Network is the Computer）”**的重要猜想，用于描述分布式计算技术带来的新世界。云计算，其实就是分布式计算的一种。</p>
<p><img src="https://yeolar.github.io/post-images/1604065021274.jpeg" alt="" loading="lazy"><br>
约翰·盖奇</p>
<p>然而，人们仍然没有对云计算引起足够的关注。</p>
<p>直到90年代，云计算相关的理念重新回到了人们的视野。不过这次它换了一个更简单的名字，叫做<strong>网格计算（Grid Computing）</strong>。</p>
<p>网格（Grid）的叫法，和我们日常理解的“网格化管理”有很大不同，它是直接照搬自电网的概念（Electric Power Grid）。它的本质目的，还是把大量机器整合成一个虚拟的超级机器，给分布在世界各地的人们使用，也就是公共计算服务。</p>
<p>1996年，康柏（Compaq）公司的一群技术主管在讨论计算业务的发展时，首次使用了Cloud Computing这个词，他们认为商业计算会向Cloud Computing的方向转移。</p>
<p><img src="https://yeolar.github.io/post-images/1604065053418.jpeg" alt="" loading="lazy"><br>
1996年11月14日，康柏公司关于cloud computing的商业计划</p>
<p><strong>这是Cloud Computing（云计算）概念的真正首次出现。</strong></p>
<p>1997年，美国教授Ramnath K. Chellappa对“Cloud Computing”这个词做出了首个学术定义：“计算边界由经济而并非完全由技术决定的计算模式”。</p>
<p><img src="https://yeolar.github.io/post-images/1604065077581.jpeg" alt="" loading="lazy"><br>
拉姆纳特·K·切拉帕（印度裔）</p>
<p>此后的云计算发展，掀起了一股小高潮——</p>
<p>1997年，InsynQ基于HP的设备上线了按需使用的应用和桌面服务。</p>
<p>1998 年，VMware公司成立，并首次引入 X86 的虚拟技术。同年，HP成立公共计算部门。</p>
<p>1999 年，MarcAndreessen创建LoudCloud，是世界上第一个商业化的IaaS平台。</p>
<p>同年，salesforce.com公司成立。这家公司是目前公认的云计算先驱，创始人是几个Oracle公司前高管。</p>
<p>公司成立之初，他们就喊出了“No Software”的口号，宣布开启”软件终结“革命。</p>
<p><img src="https://yeolar.github.io/post-images/1604065109843.png" alt="" loading="lazy"><br>
他们通过自己的互联网站点向企业提供客户关系管理（CRM）软件系统，使得企业不必像以前那样通过部署自己的软件系统来进行客户管理。这就是最早的软件即服务（SaaS）模型。</p>
<p>2000年，Sun公司发布 Sun cloud。</p>
<p>2001年，HP公司发布公共数据中心产品。</p>
<p>……</p>
<p>此时此刻，云计算已经是呼之欲出了。</p>
<h1 id="part3-亚马逊谷歌云计算的正式诞生">Part.3  亚马逊&amp;谷歌——云计算的正式诞生</h1>
<p>2000年，当时美国电子商务公司Amazon正在开发电商服务平台Merchant.com，旨在帮助第三方公司在Amazon上构建自己的在线购物网站。</p>
<p>不过，因为架构设计能力和管理流程等方面的问题，这个项目进展缓慢。</p>
<p>于是，亚马逊的管理层开始考虑，是不是可以将已有的代码进行解耦，设计成独立的API服务，然后让内部或外部应用进行服务调用。这样，既可以节约后续的开发工作量，也可以增强系统的灵活性和复用度。</p>
<p>由此，2002年亚马逊启用了**Amazon Web Services（AWS）**平台。当时该免费服务可以让企业将Amazon.com的功能整合到自家网站上。</p>
<p>2003年，安迪·杰西（Andy Jassy），当时杰夫·贝索斯（Jeff Bezos，亚马逊创始人）的秘书长，现在AWS的CEO，在贝索斯的家里召开了一次管理层会议。会上，大家决定要把应用开发的通用部分抽离出来，做一个公共基础设施服务平台，让内外部开发者可以基于这个平台开发自己的应用。</p>
<p><img src="https://yeolar.github.io/post-images/1604065144903.png" alt="" loading="lazy"><br>
安迪·杰西</p>
<p>随后，他们整理了一系列可以成为公共服务的候选模块，并从中挑了服务器、存储和数据库三个部分开始。不仅因为这三个需求最多，还因为Amazon最擅长这部分，毕竟低利润率商业模式让他在如何降低数据中心的运营成本上颇有积累。</p>
<p>2006年，亚马逊推出了两款重磅产品，分别是S3（Simple Storage Service，简单存储服务）和EC2（Elastic Cloud Computer，弹性云计算），从而奠定了自家云计算服务的基石（直至今日都无人可以撼动）。</p>
<p>在那一期间，谷歌其实也没有闲着。这家诞生于1998年的年轻公司，在2003~2006年期间，连续发表了四篇重磅文章，分别关于<strong>分布式文件系统（GFS）、并行计算（MapReduce）、数据管理（Big Table）和分布式资源管理（Chubby）</strong>。</p>
<p>这些关键技术不仅奠定了谷歌自家的云计算服务基础，也为全世界云计算、大数据的发展指明了方向。</p>
<p>2006年，27岁的Google高级工程师克里斯托夫·比希利亚第一次向Google董事长兼CEO施密特提出“云端计算”的想法。在施密特的支持下，Google推出了“Google 101计划”，并正式提出“云”的概念。</p>
<p><img src="https://yeolar.github.io/post-images/1604065163967.jpeg" alt="" loading="lazy"><br>
克里斯托夫·比希利亚</p>
<p>后来《财富》杂志10大最具头脑人物授予其“最聪明的工程师”称号</p>
<p>于是，就有了本文开头施密特发表的讲话。</p>
<p>至此，云计算揭开了神秘的面纱，正式来到了公众的面前。随后的云计算，进入了快速发展阶段，并最终渗透到了我们工作和生活的各个领域。</p>
]]></content>
    </entry>
</feed>